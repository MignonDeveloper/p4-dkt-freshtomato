{"cells":[{"cell_type":"markdown","metadata":{"id":"ZipXHWdgaQz-"},"source":["https://minimin2.tistory.com/137\n","\n","https://leo-bb.tistory.com/62?category=858291\n","\n","https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.std.html"]},{"cell_type":"markdown","metadata":{},"source":["# 결측치 많은 변수들\n","\n","'user_test_correct_cnt_per_test': 372603,\n","\n","'user_acc_per_test': 372603,\n","\n","'user_total_acc': 365164,\n","\n"," 'user_total_correct_cnt': 365164"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39644,"status":"ok","timestamp":1622559822765,"user":{"displayName":"문재훈","photoUrl":"","userId":"02977204597809886794"},"user_tz":-540},"id":"0unUz7C7YQ2b","outputId":"be8d1a71-f443-47a3-800a-e7d483b09bdf"},"outputs":[],"source":["# !pip install pycaret > /dev/null"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pycaret[full] in /opt/conda/lib/python3.7/site-packages (2.3.1)\n","Requirement already satisfied: ngboost in /opt/conda/lib/python3.7/site-packages (0.3.10)\n","Requirement already satisfied: pyLDAvis in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (3.3.1)\n","Requirement already satisfied: textblob in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (0.15.3)\n","Requirement already satisfied: numpy==1.19.5 in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (1.19.5)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (1.2.4)\n","Requirement already satisfied: pyod in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (0.8.8)\n","Requirement already satisfied: pandas-profiling>=2.8.0 in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (3.0.0)\n","Requirement already satisfied: imbalanced-learn==0.7.0 in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (0.7.0)\n","Requirement already satisfied: plotly>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (4.14.3)\n","Requirement already satisfied: yellowbrick>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (1.3.post1)\n","Requirement already satisfied: mlflow in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (1.17.0)\n","Requirement already satisfied: scipy<=1.5.4 in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (1.5.4)\n","Requirement already satisfied: cufflinks>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (0.17.3)\n","Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (3.4.2)\n","Requirement already satisfied: lightgbm>=2.3.1 in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (3.2.1)\n","Requirement already satisfied: Boruta in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (0.3)\n","Requirement already satisfied: seaborn in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (0.11.1)\n","Requirement already satisfied: wordcloud in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (1.8.1)\n","Requirement already satisfied: umap-learn in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (0.5.1)\n","Requirement already satisfied: gensim<4.0.0 in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (3.8.3)\n","Requirement already satisfied: scikit-learn==0.23.2 in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (0.23.2)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (3.6.2)\n","Requirement already satisfied: kmodes>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (0.11.0)\n","Requirement already satisfied: scikit-plot in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (0.3.7)\n","Requirement already satisfied: mlxtend>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (0.18.0)\n","Requirement already satisfied: spacy<2.4.0 in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (2.3.5)\n","Requirement already satisfied: IPython in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (7.16.1)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (1.0.1)\n","Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (7.6.3)\n","Requirement already satisfied: catboost>=0.23.2; extra == \"full\" in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (0.25.1)\n","Collecting shap; extra == \"full\"\n","  Using cached shap-0.39.0.tar.gz (356 kB)\n","Requirement already satisfied: optuna; extra == \"full\" in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (0.18.1)\n","Requirement already satisfied: tune-sklearn>=0.2.1; extra == \"full\" in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (0.3.0)\n","Requirement already satisfied: xgboost>=1.1.0; extra == \"full\" in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (1.4.2)\n","Requirement already satisfied: azure-storage-blob; extra == \"full\" in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (12.8.1)\n","Requirement already satisfied: google-cloud-storage; extra == \"full\" in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (1.38.0)\n","Requirement already satisfied: psutil; extra == \"full\" in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (5.7.0)\n","Requirement already satisfied: hyperopt; extra == \"full\" in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (0.2.5)\n","Requirement already satisfied: scikit-optimize>=0.8.1; extra == \"full\" in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (0.8.1)\n","Requirement already satisfied: awscli; extra == \"full\" in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (1.19.85)\n","Requirement already satisfied: ray[tune]>=1.0.0; extra == \"full\" in /opt/conda/lib/python3.7/site-packages (from pycaret[full]) (1.3.0)\n","Requirement already satisfied: importlib-metadata<4.0.0,>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from ngboost) (3.10.1)\n","Requirement already satisfied: tqdm<5.0,>=4.4 in /opt/conda/lib/python3.7/site-packages (from ngboost) (4.61.0)\n","Requirement already satisfied: lifelines<0.29,>=0.25 in /opt/conda/lib/python3.7/site-packages (from ngboost) (0.26.0)\n","Requirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (from pyLDAvis->pycaret[full]) (0.0)\n","Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyLDAvis->pycaret[full]) (0.18.2)\n","Requirement already satisfied: numexpr in /opt/conda/lib/python3.7/site-packages (from pyLDAvis->pycaret[full]) (2.7.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from pyLDAvis->pycaret[full]) (2.11.2)\n","Requirement already satisfied: funcy in /opt/conda/lib/python3.7/site-packages (from pyLDAvis->pycaret[full]) (1.16)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from pyLDAvis->pycaret[full]) (46.4.0.post20200518)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->pycaret[full]) (2.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->pycaret[full]) (2020.1)\n","Requirement already satisfied: statsmodels in /opt/conda/lib/python3.7/site-packages (from pyod->pycaret[full]) (0.12.2)\n","Requirement already satisfied: numba>=0.35 in /opt/conda/lib/python3.7/site-packages (from pyod->pycaret[full]) (0.53.1)\n","Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from pyod->pycaret[full]) (1.14.0)\n","Requirement already satisfied: visions[type_image_path]==0.7.1 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling>=2.8.0->pycaret[full]) (0.7.1)\n","Requirement already satisfied: pydantic>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling>=2.8.0->pycaret[full]) (1.8.2)\n","Requirement already satisfied: requests>=2.24.0 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling>=2.8.0->pycaret[full]) (2.25.1)\n","Requirement already satisfied: htmlmin>=0.1.12 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling>=2.8.0->pycaret[full]) (0.1.12)\n","Requirement already satisfied: PyYAML>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling>=2.8.0->pycaret[full]) (5.3.1)\n","Requirement already satisfied: phik>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling>=2.8.0->pycaret[full]) (0.11.2)\n","Requirement already satisfied: missingno>=0.4.2 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling>=2.8.0->pycaret[full]) (0.4.2)\n","Requirement already satisfied: tangled-up-in-unicode==0.1.0 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling>=2.8.0->pycaret[full]) (0.1.0)\n","Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from plotly>=4.4.1->pycaret[full]) (1.3.3)\n","Requirement already satisfied: cycler>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from yellowbrick>=1.0.1->pycaret[full]) (0.10.0)\n","Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret[full]) (0.3)\n","Requirement already satisfied: sqlparse>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret[full]) (0.4.1)\n","Requirement already satisfied: Flask in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret[full]) (2.0.1)\n","Requirement already satisfied: alembic<=1.4.1 in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret[full]) (1.4.1)\n","Requirement already satisfied: gunicorn; platform_system != \"Windows\" in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret[full]) (20.1.0)\n","Requirement already satisfied: querystring-parser in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret[full]) (1.2.4)\n","Requirement already satisfied: gitpython>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret[full]) (3.1.17)\n","Requirement already satisfied: databricks-cli>=0.8.7 in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret[full]) (0.14.3)\n","Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret[full]) (1.4.15)\n","Requirement already satisfied: docker>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret[full]) (5.0.0)\n","Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret[full]) (8.0.1)\n","Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret[full]) (1.6.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret[full]) (3.17.0)\n","Requirement already satisfied: prometheus-flask-exporter in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret[full]) (0.18.2)\n","Requirement already satisfied: colorlover>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from cufflinks>=0.17.0->pycaret[full]) (0.3.0)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pycaret[full]) (7.2.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pycaret[full]) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pycaret[full]) (1.3.1)\n","Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm>=2.3.1->pycaret[full]) (0.34.2)\n","Requirement already satisfied: pynndescent>=0.5 in /opt/conda/lib/python3.7/site-packages (from umap-learn->pycaret[full]) (0.5.2)\n","Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim<4.0.0->pycaret[full]) (5.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.23.2->pycaret[full]) (2.1.0)\n","Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from nltk->pycaret[full]) (2021.4.4)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0->pycaret[full]) (0.8.2)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0->pycaret[full]) (1.0.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0->pycaret[full]) (1.0.5)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0->pycaret[full]) (0.7.4)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0->pycaret[full]) (1.0.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0->pycaret[full]) (1.1.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0->pycaret[full]) (2.0.5)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0->pycaret[full]) (3.0.5)\n","Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0->pycaret[full]) (7.4.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from IPython->pycaret[full]) (3.0.5)\n","Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from IPython->pycaret[full]) (4.3.3)\n","Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from IPython->pycaret[full]) (2.6.1)\n","Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from IPython->pycaret[full]) (4.4.2)\n","Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from IPython->pycaret[full]) (0.17.1)\n","Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from IPython->pycaret[full]) (0.7.5)\n","Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from IPython->pycaret[full]) (0.2.0)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from IPython->pycaret[full]) (4.8.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /opt/conda/lib/python3.7/site-packages (from ipywidgets->pycaret[full]) (1.0.0)\n","Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets->pycaret[full]) (5.5.5)\n","Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets->pycaret[full]) (5.1.3)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets->pycaret[full]) (3.5.1)\n","Requirement already satisfied: graphviz in /opt/conda/lib/python3.7/site-packages (from catboost>=0.23.2; extra == \"full\"->pycaret[full]) (0.16)\n","Requirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.7/site-packages (from shap; extra == \"full\"->pycaret[full]) (0.0.7)\n","Requirement already satisfied: typing in /opt/conda/lib/python3.7/site-packages (from optuna; extra == \"full\"->pycaret[full]) (3.7.4.3)\n","Requirement already satisfied: cliff in /opt/conda/lib/python3.7/site-packages (from optuna; extra == \"full\"->pycaret[full]) (3.7.0)\n","Requirement already satisfied: colorlog in /opt/conda/lib/python3.7/site-packages (from optuna; extra == \"full\"->pycaret[full]) (5.0.1)\n","Requirement already satisfied: cryptography>=2.1.4 in /opt/conda/lib/python3.7/site-packages (from azure-storage-blob; extra == \"full\"->pycaret[full]) (2.9.2)\n","Requirement already satisfied: azure-core<2.0.0,>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from azure-storage-blob; extra == \"full\"->pycaret[full]) (1.14.0)\n","Requirement already satisfied: msrest>=0.6.18 in /opt/conda/lib/python3.7/site-packages (from azure-storage-blob; extra == \"full\"->pycaret[full]) (0.6.21)\n","Requirement already satisfied: google-resumable-media<2.0dev,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage; extra == \"full\"->pycaret[full]) (1.3.0)\n","Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage; extra == \"full\"->pycaret[full]) (1.6.0)\n","Requirement already satisfied: google-auth<2.0dev,>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage; extra == \"full\"->pycaret[full]) (1.30.1)\n","Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from hyperopt; extra == \"full\"->pycaret[full]) (2.5.1)\n","Requirement already satisfied: pyaml>=16.9 in /opt/conda/lib/python3.7/site-packages (from scikit-optimize>=0.8.1; extra == \"full\"->pycaret[full]) (20.4.0)\n","Requirement already satisfied: colorama<0.4.4,>=0.2.5 in /opt/conda/lib/python3.7/site-packages (from awscli; extra == \"full\"->pycaret[full]) (0.4.3)\n","Requirement already satisfied: botocore==1.20.85 in /opt/conda/lib/python3.7/site-packages (from awscli; extra == \"full\"->pycaret[full]) (1.20.85)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from awscli; extra == \"full\"->pycaret[full]) (0.15.2)\n","Requirement already satisfied: rsa<4.8,>=3.1.2; python_version > \"2.7\" in /opt/conda/lib/python3.7/site-packages (from awscli; extra == \"full\"->pycaret[full]) (4.7.2)\n","Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from awscli; extra == \"full\"->pycaret[full]) (0.4.2)\n","Requirement already satisfied: aiohttp-cors in /opt/conda/lib/python3.7/site-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (0.7.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (3.0.12)\n","Requirement already satisfied: grpcio>=1.28.1 in /opt/conda/lib/python3.7/site-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (1.38.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (1.0.2)\n","Requirement already satisfied: prometheus-client>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (0.10.1)\n","Requirement already satisfied: aioredis in /opt/conda/lib/python3.7/site-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (1.3.1)\n","Requirement already satisfied: gpustat in /opt/conda/lib/python3.7/site-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (0.6.0)\n","Requirement already satisfied: opencensus in /opt/conda/lib/python3.7/site-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (0.7.13)\n","Requirement already satisfied: jsonschema in /opt/conda/lib/python3.7/site-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (3.2.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (3.7.4.post0)\n","Requirement already satisfied: py-spy>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (0.3.7)\n","Requirement already satisfied: redis>=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (3.5.3)\n","Requirement already satisfied: tensorboardX; extra == \"tune\" in /opt/conda/lib/python3.7/site-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (2.2)\n","Requirement already satisfied: tabulate; extra == \"tune\" in /opt/conda/lib/python3.7/site-packages (from ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (0.8.9)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<4.0.0,>=3.4.0->ngboost) (3.10.0.0)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<4.0.0,>=3.4.0->ngboost) (3.4.1)\n","Requirement already satisfied: autograd-gamma>=0.3 in /opt/conda/lib/python3.7/site-packages (from lifelines<0.29,>=0.25->ngboost) (0.5.0)\n","Requirement already satisfied: formulaic<0.3,>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from lifelines<0.29,>=0.25->ngboost) (0.2.3)\n","Requirement already satisfied: autograd>=1.3 in /opt/conda/lib/python3.7/site-packages (from lifelines<0.29,>=0.25->ngboost) (1.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->pyLDAvis->pycaret[full]) (1.1.1)\n","Requirement already satisfied: patsy>=0.5 in /opt/conda/lib/python3.7/site-packages (from statsmodels->pyod->pycaret[full]) (0.5.1)\n","Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba>=0.35->pyod->pycaret[full]) (0.36.0)\n","Requirement already satisfied: multimethod==1.4 in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret[full]) (1.4)\n","Requirement already satisfied: bottleneck in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret[full]) (1.3.2)\n","Requirement already satisfied: attrs>=19.3.0 in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret[full]) (21.2.0)\n","Requirement already satisfied: imagehash; extra == \"type_image_path\" in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret[full]) (4.2.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret[full]) (2020.6.20)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret[full]) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret[full]) (2.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret[full]) (1.25.8)\n","Requirement already satisfied: Werkzeug>=2.0 in /opt/conda/lib/python3.7/site-packages (from Flask->mlflow->pycaret[full]) (2.0.1)\n","Requirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.7/site-packages (from Flask->mlflow->pycaret[full]) (2.0.1)\n","Requirement already satisfied: python-editor>=0.3 in /opt/conda/lib/python3.7/site-packages (from alembic<=1.4.1->mlflow->pycaret[full]) (1.0.4)\n","Requirement already satisfied: Mako in /opt/conda/lib/python3.7/site-packages (from alembic<=1.4.1->mlflow->pycaret[full]) (1.1.4)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from gitpython>=2.1.0->mlflow->pycaret[full]) (4.0.7)\n","Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from sqlalchemy->mlflow->pycaret[full]) (1.1.0)\n","Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from docker>=4.0.0->mlflow->pycaret[full]) (1.0.1)\n","Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->pycaret[full]) (0.2.5)\n","Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.2->IPython->pycaret[full]) (0.2.0)\n","Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->IPython->pycaret[full]) (0.7.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->IPython->pycaret[full]) (0.6.0)\n","Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret[full]) (6.1)\n","Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret[full]) (6.1.12)\n","Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets->pycaret[full]) (4.7.1)\n","Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (6.4.0)\n","Requirement already satisfied: cmd2>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna; extra == \"full\"->pycaret[full]) (1.5.0)\n","Requirement already satisfied: stevedore>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna; extra == \"full\"->pycaret[full]) (3.3.0)\n","Requirement already satisfied: PrettyTable>=0.7.2 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna; extra == \"full\"->pycaret[full]) (2.1.0)\n","Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna; extra == \"full\"->pycaret[full]) (5.6.0)\n","Requirement already satisfied: cffi!=1.11.3,>=1.8 in /opt/conda/lib/python3.7/site-packages (from cryptography>=2.1.4->azure-storage-blob; extra == \"full\"->pycaret[full]) (1.14.0)\n","Requirement already satisfied: isodate>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from msrest>=0.6.18->azure-storage-blob; extra == \"full\"->pycaret[full]) (0.6.0)\n","Requirement already satisfied: requests-oauthlib>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from msrest>=0.6.18->azure-storage-blob; extra == \"full\"->pycaret[full]) (1.3.0)\n","Requirement already satisfied: google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\" in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage; extra == \"full\"->pycaret[full]) (1.1.2)\n","Requirement already satisfied: google-api-core<2.0.0dev,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage; extra == \"full\"->pycaret[full]) (1.28.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage; extra == \"full\"->pycaret[full]) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage; extra == \"full\"->pycaret[full]) (4.2.2)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from botocore==1.20.85->awscli; extra == \"full\"->pycaret[full]) (0.10.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.8,>=3.1.2; python_version > \"2.7\"->awscli; extra == \"full\"->pycaret[full]) (0.4.8)\n","Requirement already satisfied: hiredis in /opt/conda/lib/python3.7/site-packages (from aioredis->ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (2.0.0)\n","Requirement already satisfied: async-timeout in /opt/conda/lib/python3.7/site-packages (from aioredis->ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (3.0.1)\n","Requirement already satisfied: blessings>=1.6 in /opt/conda/lib/python3.7/site-packages (from gpustat->ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (1.7)\n","Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /opt/conda/lib/python3.7/site-packages (from gpustat->ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (7.352.0)\n","Requirement already satisfied: opencensus-context==0.1.2 in /opt/conda/lib/python3.7/site-packages (from opencensus->ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (0.1.2)\n","Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (0.17.3)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (5.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->ray[tune]>=1.0.0; extra == \"full\"->pycaret[full]) (1.6.3)\n","Requirement already satisfied: astor in /opt/conda/lib/python3.7/site-packages (from formulaic<0.3,>=0.2.2->lifelines<0.29,>=0.25->ngboost) (0.8.1)\n","Requirement already satisfied: wrapt in /opt/conda/lib/python3.7/site-packages (from formulaic<0.3,>=0.2.2->lifelines<0.29,>=0.25->ngboost) (1.12.1)\n","Requirement already satisfied: interface-meta>=1.2 in /opt/conda/lib/python3.7/site-packages (from formulaic<0.3,>=0.2.2->lifelines<0.29,>=0.25->ngboost) (1.2.3)\n","Requirement already satisfied: PyWavelets in /opt/conda/lib/python3.7/site-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret[full]) (1.1.1)\n","Requirement already satisfied: smmap<5,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow->pycaret[full]) (4.0.0)\n","Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret[full]) (22.0.3)\n","Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (20.1.0)\n","Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (0.10.0)\n","Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (6.0.7)\n","Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (1.5.0)\n","Requirement already satisfied: pyperclip>=1.6 in /opt/conda/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna; extra == \"full\"->pycaret[full]) (1.8.2)\n","Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.1.4->azure-storage-blob; extra == \"full\"->pycaret[full]) (2.20)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-storage-blob; extra == \"full\"->pycaret[full]) (3.1.1)\n","Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage; extra == \"full\"->pycaret[full]) (20.9)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage; extra == \"full\"->pycaret[full]) (1.53.0)\n","Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (3.3.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (1.4.3)\n","Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (0.5.0)\n","Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (0.1.2)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (0.8.4)\n","Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (0.7.1)\n","Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (0.5.3)\n","Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (0.5.1)\n","Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (1.5.1)\n","Requirement already satisfied: async-generator in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret[full]) (1.10)\n","Building wheels for collected packages: shap\n","  Building wheel for shap (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Command errored out with exit status 1:\n","   command: /opt/conda/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-omryoqjp/shap/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-omryoqjp/shap/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-n7ep_cfz\n","       cwd: /tmp/pip-install-omryoqjp/shap/\n","  Complete output (119 lines):\n","  The nvcc binary could not be located in your $PATH. Either  add it to your path, or set $CUDAHOME to enable CUDA\n","  Error building cuda module: TypeError('cannot unpack non-iterable NoneType object')\n","  WARNING: Could not compile cuda extensions\n","  running bdist_wheel\n","  running build\n","  running build_py\n","  creating build\n","  creating build/lib.linux-x86_64-3.7\n","  creating build/lib.linux-x86_64-3.7/shap\n","  copying shap/__init__.py -> build/lib.linux-x86_64-3.7/shap\n","  copying shap/_serializable.py -> build/lib.linux-x86_64-3.7/shap\n","  copying shap/links.py -> build/lib.linux-x86_64-3.7/shap\n","  copying shap/_explanation.py -> build/lib.linux-x86_64-3.7/shap\n","  copying shap/datasets.py -> build/lib.linux-x86_64-3.7/shap\n","  creating build/lib.linux-x86_64-3.7/shap/explainers\n","  copying shap/explainers/_explainer.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","  copying shap/explainers/_partition.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","  copying shap/explainers/_exact.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","  copying shap/explainers/_linear.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","  copying shap/explainers/__init__.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","  copying shap/explainers/_additive.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","  copying shap/explainers/_permutation.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","  copying shap/explainers/_gpu_tree.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","  copying shap/explainers/_sampling.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","  copying shap/explainers/_kernel.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","  copying shap/explainers/pytree.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","  copying shap/explainers/_tree.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","  copying shap/explainers/_gradient.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","  copying shap/explainers/mimic.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","  copying shap/explainers/tf_utils.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","  creating build/lib.linux-x86_64-3.7/shap/explainers/other\n","  copying shap/explainers/other/_maple.py -> build/lib.linux-x86_64-3.7/shap/explainers/other\n","  copying shap/explainers/other/_treegain.py -> build/lib.linux-x86_64-3.7/shap/explainers/other\n","  copying shap/explainers/other/__init__.py -> build/lib.linux-x86_64-3.7/shap/explainers/other\n","  copying shap/explainers/other/_random.py -> build/lib.linux-x86_64-3.7/shap/explainers/other\n","  copying shap/explainers/other/_lime.py -> build/lib.linux-x86_64-3.7/shap/explainers/other\n","  copying shap/explainers/other/_coefficent.py -> build/lib.linux-x86_64-3.7/shap/explainers/other\n","  creating build/lib.linux-x86_64-3.7/shap/explainers/_deep\n","  copying shap/explainers/_deep/deep_tf.py -> build/lib.linux-x86_64-3.7/shap/explainers/_deep\n","  copying shap/explainers/_deep/__init__.py -> build/lib.linux-x86_64-3.7/shap/explainers/_deep\n","  copying shap/explainers/_deep/deep_pytorch.py -> build/lib.linux-x86_64-3.7/shap/explainers/_deep\n","  creating build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_partial_dependence.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_bar.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_labels.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_utils.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_decision.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_monitoring.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_text.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_image.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_beeswarm.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_force_matplotlib.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_heatmap.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/__init__.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_scatter.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_force.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_violin.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_group_difference.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_embedding.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  copying shap/plots/_waterfall.py -> build/lib.linux-x86_64-3.7/shap/plots\n","  creating build/lib.linux-x86_64-3.7/shap/plots/colors\n","  copying shap/plots/colors/__init__.py -> build/lib.linux-x86_64-3.7/shap/plots/colors\n","  copying shap/plots/colors/_colorconv.py -> build/lib.linux-x86_64-3.7/shap/plots/colors\n","  copying shap/plots/colors/_colors.py -> build/lib.linux-x86_64-3.7/shap/plots/colors\n","  creating build/lib.linux-x86_64-3.7/shap/benchmark\n","  copying shap/benchmark/experiments.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","  copying shap/benchmark/methods.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","  copying shap/benchmark/__init__.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","  copying shap/benchmark/perturbation.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","  copying shap/benchmark/framework.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","  copying shap/benchmark/metrics.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","  copying shap/benchmark/plots.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","  copying shap/benchmark/measures.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","  copying shap/benchmark/models.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","  creating build/lib.linux-x86_64-3.7/shap/maskers\n","  copying shap/maskers/_tabular.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","  copying shap/maskers/_masker.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","  copying shap/maskers/_text.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","  copying shap/maskers/_image.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","  copying shap/maskers/__init__.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","  copying shap/maskers/_fixed.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","  copying shap/maskers/_fixed_composite.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","  copying shap/maskers/_output_composite.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","  copying shap/maskers/_composite.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","  creating build/lib.linux-x86_64-3.7/shap/utils\n","  copying shap/utils/_keras.py -> build/lib.linux-x86_64-3.7/shap/utils\n","  copying shap/utils/_legacy.py -> build/lib.linux-x86_64-3.7/shap/utils\n","  copying shap/utils/_general.py -> build/lib.linux-x86_64-3.7/shap/utils\n","  copying shap/utils/__init__.py -> build/lib.linux-x86_64-3.7/shap/utils\n","  copying shap/utils/_masked_model.py -> build/lib.linux-x86_64-3.7/shap/utils\n","  copying shap/utils/transformers.py -> build/lib.linux-x86_64-3.7/shap/utils\n","  copying shap/utils/_clustering.py -> build/lib.linux-x86_64-3.7/shap/utils\n","  copying shap/utils/image.py -> build/lib.linux-x86_64-3.7/shap/utils\n","  copying shap/utils/_show_progress.py -> build/lib.linux-x86_64-3.7/shap/utils\n","  creating build/lib.linux-x86_64-3.7/shap/actions\n","  copying shap/actions/_optimizer.py -> build/lib.linux-x86_64-3.7/shap/actions\n","  copying shap/actions/_action.py -> build/lib.linux-x86_64-3.7/shap/actions\n","  copying shap/actions/__init__.py -> build/lib.linux-x86_64-3.7/shap/actions\n","  creating build/lib.linux-x86_64-3.7/shap/models\n","  copying shap/models/_model.py -> build/lib.linux-x86_64-3.7/shap/models\n","  copying shap/models/_text_generation.py -> build/lib.linux-x86_64-3.7/shap/models\n","  copying shap/models/__init__.py -> build/lib.linux-x86_64-3.7/shap/models\n","  copying shap/models/_topk_lm.py -> build/lib.linux-x86_64-3.7/shap/models\n","  copying shap/models/_teacher_forcing.py -> build/lib.linux-x86_64-3.7/shap/models\n","  copying shap/models/_transformers_pipeline.py -> build/lib.linux-x86_64-3.7/shap/models\n","  creating build/lib.linux-x86_64-3.7/shap/plots/resources\n","  copying shap/plots/resources/bundle.js -> build/lib.linux-x86_64-3.7/shap/plots/resources\n","  copying shap/plots/resources/logoSmallGray.png -> build/lib.linux-x86_64-3.7/shap/plots/resources\n","  creating build/lib.linux-x86_64-3.7/shap/cext\n","  copying shap/cext/tree_shap.h -> build/lib.linux-x86_64-3.7/shap/cext\n","  running build_ext\n","  numpy.get_include() /opt/conda/lib/python3.7/site-packages/numpy/core/include\n","  building 'shap._cext' extension\n","  creating build/temp.linux-x86_64-3.7\n","  creating build/temp.linux-x86_64-3.7/shap\n","  creating build/temp.linux-x86_64-3.7/shap/cext\n","  gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/include/python3.7m -I/opt/conda/lib/python3.7/site-packages/numpy/core/include -c shap/cext/_cext.cc -o build/temp.linux-x86_64-3.7/shap/cext/_cext.o\n","  gcc: error trying to exec 'cc1plus': execvp: No such file or directory\n","  error: command 'gcc' failed with exit status 1\n","  ----------------------------------------\u001b[0m\n","\u001b[31m  ERROR: Failed building wheel for shap\u001b[0m\n","\u001b[?25h  Running setup.py clean for shap\n","Failed to build shap\n","Installing collected packages: shap\n","    Running setup.py install for shap ... \u001b[?25lerror\n","\u001b[31m    ERROR: Command errored out with exit status 1:\n","     command: /opt/conda/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-omryoqjp/shap/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-omryoqjp/shap/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-fvlfjfib/install-record.txt --single-version-externally-managed --compile --install-headers /opt/conda/include/python3.7m/shap\n","         cwd: /tmp/pip-install-omryoqjp/shap/\n","    Complete output (119 lines):\n","    The nvcc binary could not be located in your $PATH. Either  add it to your path, or set $CUDAHOME to enable CUDA\n","    Error building cuda module: TypeError('cannot unpack non-iterable NoneType object')\n","    WARNING: Could not compile cuda extensions\n","    running install\n","    running build\n","    running build_py\n","    creating build\n","    creating build/lib.linux-x86_64-3.7\n","    creating build/lib.linux-x86_64-3.7/shap\n","    copying shap/__init__.py -> build/lib.linux-x86_64-3.7/shap\n","    copying shap/_serializable.py -> build/lib.linux-x86_64-3.7/shap\n","    copying shap/links.py -> build/lib.linux-x86_64-3.7/shap\n","    copying shap/_explanation.py -> build/lib.linux-x86_64-3.7/shap\n","    copying shap/datasets.py -> build/lib.linux-x86_64-3.7/shap\n","    creating build/lib.linux-x86_64-3.7/shap/explainers\n","    copying shap/explainers/_explainer.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","    copying shap/explainers/_partition.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","    copying shap/explainers/_exact.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","    copying shap/explainers/_linear.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","    copying shap/explainers/__init__.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","    copying shap/explainers/_additive.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","    copying shap/explainers/_permutation.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","    copying shap/explainers/_gpu_tree.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","    copying shap/explainers/_sampling.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","    copying shap/explainers/_kernel.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","    copying shap/explainers/pytree.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","    copying shap/explainers/_tree.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","    copying shap/explainers/_gradient.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","    copying shap/explainers/mimic.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","    copying shap/explainers/tf_utils.py -> build/lib.linux-x86_64-3.7/shap/explainers\n","    creating build/lib.linux-x86_64-3.7/shap/explainers/other\n","    copying shap/explainers/other/_maple.py -> build/lib.linux-x86_64-3.7/shap/explainers/other\n","    copying shap/explainers/other/_treegain.py -> build/lib.linux-x86_64-3.7/shap/explainers/other\n","    copying shap/explainers/other/__init__.py -> build/lib.linux-x86_64-3.7/shap/explainers/other\n","    copying shap/explainers/other/_random.py -> build/lib.linux-x86_64-3.7/shap/explainers/other\n","    copying shap/explainers/other/_lime.py -> build/lib.linux-x86_64-3.7/shap/explainers/other\n","    copying shap/explainers/other/_coefficent.py -> build/lib.linux-x86_64-3.7/shap/explainers/other\n","    creating build/lib.linux-x86_64-3.7/shap/explainers/_deep\n","    copying shap/explainers/_deep/deep_tf.py -> build/lib.linux-x86_64-3.7/shap/explainers/_deep\n","    copying shap/explainers/_deep/__init__.py -> build/lib.linux-x86_64-3.7/shap/explainers/_deep\n","    copying shap/explainers/_deep/deep_pytorch.py -> build/lib.linux-x86_64-3.7/shap/explainers/_deep\n","    creating build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_partial_dependence.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_bar.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_labels.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_utils.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_decision.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_monitoring.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_text.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_image.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_beeswarm.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_force_matplotlib.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_heatmap.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/__init__.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_scatter.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_force.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_violin.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_group_difference.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_embedding.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    copying shap/plots/_waterfall.py -> build/lib.linux-x86_64-3.7/shap/plots\n","    creating build/lib.linux-x86_64-3.7/shap/plots/colors\n","    copying shap/plots/colors/__init__.py -> build/lib.linux-x86_64-3.7/shap/plots/colors\n","    copying shap/plots/colors/_colorconv.py -> build/lib.linux-x86_64-3.7/shap/plots/colors\n","    copying shap/plots/colors/_colors.py -> build/lib.linux-x86_64-3.7/shap/plots/colors\n","    creating build/lib.linux-x86_64-3.7/shap/benchmark\n","    copying shap/benchmark/experiments.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","    copying shap/benchmark/methods.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","    copying shap/benchmark/__init__.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","    copying shap/benchmark/perturbation.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","    copying shap/benchmark/framework.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","    copying shap/benchmark/metrics.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","    copying shap/benchmark/plots.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","    copying shap/benchmark/measures.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","    copying shap/benchmark/models.py -> build/lib.linux-x86_64-3.7/shap/benchmark\n","    creating build/lib.linux-x86_64-3.7/shap/maskers\n","    copying shap/maskers/_tabular.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","    copying shap/maskers/_masker.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","    copying shap/maskers/_text.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","    copying shap/maskers/_image.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","    copying shap/maskers/__init__.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","    copying shap/maskers/_fixed.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","    copying shap/maskers/_fixed_composite.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","    copying shap/maskers/_output_composite.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","    copying shap/maskers/_composite.py -> build/lib.linux-x86_64-3.7/shap/maskers\n","    creating build/lib.linux-x86_64-3.7/shap/utils\n","    copying shap/utils/_keras.py -> build/lib.linux-x86_64-3.7/shap/utils\n","    copying shap/utils/_legacy.py -> build/lib.linux-x86_64-3.7/shap/utils\n","    copying shap/utils/_general.py -> build/lib.linux-x86_64-3.7/shap/utils\n","    copying shap/utils/__init__.py -> build/lib.linux-x86_64-3.7/shap/utils\n","    copying shap/utils/_masked_model.py -> build/lib.linux-x86_64-3.7/shap/utils\n","    copying shap/utils/transformers.py -> build/lib.linux-x86_64-3.7/shap/utils\n","    copying shap/utils/_clustering.py -> build/lib.linux-x86_64-3.7/shap/utils\n","    copying shap/utils/image.py -> build/lib.linux-x86_64-3.7/shap/utils\n","    copying shap/utils/_show_progress.py -> build/lib.linux-x86_64-3.7/shap/utils\n","    creating build/lib.linux-x86_64-3.7/shap/actions\n","    copying shap/actions/_optimizer.py -> build/lib.linux-x86_64-3.7/shap/actions\n","    copying shap/actions/_action.py -> build/lib.linux-x86_64-3.7/shap/actions\n","    copying shap/actions/__init__.py -> build/lib.linux-x86_64-3.7/shap/actions\n","    creating build/lib.linux-x86_64-3.7/shap/models\n","    copying shap/models/_model.py -> build/lib.linux-x86_64-3.7/shap/models\n","    copying shap/models/_text_generation.py -> build/lib.linux-x86_64-3.7/shap/models\n","    copying shap/models/__init__.py -> build/lib.linux-x86_64-3.7/shap/models\n","    copying shap/models/_topk_lm.py -> build/lib.linux-x86_64-3.7/shap/models\n","    copying shap/models/_teacher_forcing.py -> build/lib.linux-x86_64-3.7/shap/models\n","    copying shap/models/_transformers_pipeline.py -> build/lib.linux-x86_64-3.7/shap/models\n","    creating build/lib.linux-x86_64-3.7/shap/plots/resources\n","    copying shap/plots/resources/bundle.js -> build/lib.linux-x86_64-3.7/shap/plots/resources\n","    copying shap/plots/resources/logoSmallGray.png -> build/lib.linux-x86_64-3.7/shap/plots/resources\n","    creating build/lib.linux-x86_64-3.7/shap/cext\n","    copying shap/cext/tree_shap.h -> build/lib.linux-x86_64-3.7/shap/cext\n","    running build_ext\n","    numpy.get_include() /opt/conda/lib/python3.7/site-packages/numpy/core/include\n","    building 'shap._cext' extension\n","    creating build/temp.linux-x86_64-3.7\n","    creating build/temp.linux-x86_64-3.7/shap\n","    creating build/temp.linux-x86_64-3.7/shap/cext\n","    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/include/python3.7m -I/opt/conda/lib/python3.7/site-packages/numpy/core/include -c shap/cext/_cext.cc -o build/temp.linux-x86_64-3.7/shap/cext/_cext.o\n","    gcc: error trying to exec 'cc1plus': execvp: No such file or directory\n","    error: command 'gcc' failed with exit status 1\n","    ----------------------------------------\u001b[0m\n","\u001b[?25h\u001b[31mERROR: Command errored out with exit status 1: /opt/conda/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-omryoqjp/shap/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-omryoqjp/shap/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-fvlfjfib/install-record.txt --single-version-externally-managed --compile --install-headers /opt/conda/include/python3.7m/shap Check the logs for full command output.\u001b[0m\n"]}],"source":["!pip install pycaret[full] ngboost\n"]},{"cell_type":"markdown","metadata":{"id":"yQO9VJswFGRt"},"source":["# LGBM with pycaret\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"gq_6e-6RFGRv"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import random\n","import pickle\n","from pycaret.classification import *\n","from pycaret.utils import check_metric\n","import time\n","from datetime import timedelta, timezone, datetime\n","from copy import deepcopy\n","from collections import defaultdict\n","from tqdm import tqdm_notebook, tqdm\n","import json"]},{"cell_type":"markdown","metadata":{"id":"62_TwoqRFGRw"},"source":["# 데이터 가져오기"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"drlrOZ3hroWh"},"outputs":[],"source":["upper_dir = '/opt/p4-dkt-freshtomato/input/data/train_dataset'\n","train_path = f'{upper_dir}/train_data.csv'\n","test_path = f'{upper_dir}/test_data.csv'\n","submission_path = f'{upper_dir}/sample_submission.csv'"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"hERUJHdAAz2J"},"outputs":[],"source":["train = pd.read_csv(train_path) \n","test = pd.read_csv(test_path)\n","\n","answerCode2bool = {'userID':object,  'answerCode': 'int16', 'KnowledgeTag':object}\n","train = train.astype(answerCode2bool)\n","test = test.astype(answerCode2bool)\n","# train.Timestamp = pd.to_datetime(train.Timestamp)\n","# test.Timestamp = pd.to_datetime(test.Timestamp)"]},{"cell_type":"markdown","metadata":{"id":"sDSFqsJJFGRx"},"source":["# Feature Engineering"]},{"cell_type":"markdown","metadata":{"id":"nwJ2Vgz6EdxJ"},"source":["## Train에서 미리 추출해야할 변수들"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":951,"status":"ok","timestamp":1622563551239,"user":{"displayName":"문재훈","photoUrl":"","userId":"02977204597809886794"},"user_tz":-540},"id":"TvhQlwqnErzf","outputId":"de1f5ff9-6c6a-493d-c311-1b9f5c92ed25"},"outputs":[],"source":["# # trian에서 각 문제별 통계량 추출\n","# # 아래의 피쳐들은 train에서 뽑은 값들을 test에 대입해주어야함.\n","\n","# testId_mean_sum_count = train.groupby(['testId'])['answerCode'].agg(['mean','sum','count']).to_dict()\n","# assessmentItemID_mean_sum_count = train.groupby(['assessmentItemID'])['answerCode'].agg(['mean', 'sum','count']).to_dict()\n","# KnowledgeTag_mean_sum_count = train.groupby(['KnowledgeTag'])['answerCode'].agg(['mean', 'sum','count']).to_dict()\n","\n","total_num_prob_in_test = train[['assessmentItemID', 'testId']].drop_duplicates().groupby('testId').size()  \n","testid_maxlen_dict = total_num_prob_in_test.to_dict()\n","\n","# LB Prediction해야하는 문항 ID들을 파악\n","set_assessmentItemID = set(test.loc[test.answerCode == -1, 'assessmentItemID'].values)\n","set_testID = set(test.loc[test.answerCode == -1, 'testId'].values)"]},{"cell_type":"markdown","metadata":{"id":"3vwnt67Tg-lt"},"source":["## Input Data에 대해서 만들어줘야 하는 피쳐들"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def minyong_feature(df):\n","    df['test_pre'] = df.testId.map(lambda x: int(x[1:4]))\n","    df['test_post'] = df.testId.map(lambda x: int(x[-3:]))\n","    return df"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"28WlJMYjFGRx"},"outputs":[],"source":["def ara_featunre(df):\n","    # ------- user의 평균 문제 풀이 시간 (시험지 별 체크)\n","    next_df = df.shift(-1).fillna(-1)\n","    prev_df = df.shift(1).fillna(-1)\n","    df[\"diff\"] = pd.to_datetime(next_df[\"Timestamp\"]) - pd.to_datetime(df[\"Timestamp\"])\n","\n","    pr_user_id = df[\"userID\"][0]\n","    pr_test_num, diff = 1, 0\n","    user_current_test = defaultdict(int)\n","    user_ox_count = dict()\n","    user_continue_ox_count = dict()\n","    user_assessmentnum_answerrate = dict()\n","\n","    user_assessment_avg, user_test_done_time = [], []\n","    user_answer_cnt, user_wrong_cnt = [], []\n","    user_continue_answer_cnt, user_continue_wrong_cnt = [], []\n","    user_test_answer_rate = []\n","    i=-1\n","    for user_id, pr_test, pr_assess, nx_test, nx_assess, diff_time, prev_answer in tqdm(zip(df[\"userID\"], df[\"testId\"], df[\"assessmentItemID\"], next_df[\"testId\"], next_df[\"assessmentItemID\"], df[\"diff\"], prev_df[\"answerCode\"])):\n","        i+=1\n","\n","        if user_id != pr_user_id: # 다른 user 시작\n","            pr_test_num, diff = 1, 0\n","            user_current_test = defaultdict(int)\n","            user_ox_count = dict()\n","            user_continue_ox_count = dict()\n","            user_assessmentnum_answerrate = dict()\n","            pr_user_id = user_id\n","            prev_answer = -1\n","        \n","        if user_current_test[pr_test] == 0 or nx_test == -1: # 새로운 시험지거나 맨 마지막일 경우\n","            prev_answer = -1\n","        \n","        if pr_test not in user_current_test:\n","            user_current_test[pr_test] = 1 # 현재 시험지의 푼 문항 수 체크\n","        else:\n","            user_current_test[pr_test] += 1\n","        \n","        if pr_test not in user_ox_count:\n","            prev_count = [1, 0] if prev_answer == 1 else [0, 1] # Answer / Wrong count\n","            prev_num_rate = [1, 1, 1.0] if prev_answer == 1 else [1, 0, 0.0] # 푼 문제 수, 현재까지 정답 수, 정답률\n","            if prev_answer == -1:\n","                prev_count = [0, 0]\n","            \n","            user_ox_count[pr_test] = deepcopy(prev_count)\n","            user_continue_ox_count[pr_test] = deepcopy(prev_count)\n","            user_assessmentnum_answerrate[pr_test] = deepcopy(prev_num_rate) # 시험지 별 푼 문항 수, 정답률\n","        else:\n","            if prev_answer == 1:\n","                user_ox_count[pr_test][0] += 1\n","                user_continue_ox_count[pr_test][0] += 1 # 이전 답이 1 이라면 +1\n","                user_continue_ox_count[pr_test][1] = 0  # 연속 오답 count는 초기화\n","                user_assessmentnum_answerrate[pr_test][0] += 1 # 푼 문항 수 증가\n","                user_assessmentnum_answerrate[pr_test][1] += 1 # 푼 문항 중 정답수 증가\n","        \n","            else:\n","                user_ox_count[pr_test][1] += 1\n","                user_continue_ox_count[pr_test][0] = 0  # 연속정답 count는 초기화\n","                user_continue_ox_count[pr_test][1] += 1 # 이전 답이 0 이라면 +1\n","                user_assessmentnum_answerrate[pr_test][0] += 1 # 푼 문항 수 증가\n","        \n","        user_assessmentnum_answerrate[pr_test][2] = user_assessmentnum_answerrate[pr_test][1]/user_assessmentnum_answerrate[pr_test][0] # 정답률 갱신\n","\n","        user_answer_cnt.append(user_ox_count[pr_test][0])\n","        user_wrong_cnt.append(user_ox_count[pr_test][1])\n","\n","        user_continue_answer_cnt.append(user_continue_ox_count[pr_test][0])\n","        user_continue_wrong_cnt.append(user_continue_ox_count[pr_test][1])\n","\n","        user_test_answer_rate.append(user_assessmentnum_answerrate[pr_test][2])\n","\n","\n","        if user_current_test[pr_test] == testid_maxlen_dict[pr_test]: # 시험지의 문제를 모두 다 풀었다면\n","            del user_current_test[pr_test] # 풀고있는 시험지에서 제외 (모두 다 풀었음)\n","            del user_ox_count[pr_test]\n","            del user_continue_ox_count[pr_test]\n","            del user_assessmentnum_answerrate[pr_test]\n","\n","        if len(user_current_test) == 0 or nx_test == -1: # 만약 usre가 시작한 시험지를 모두 푸는데 완료했다면\n","            user_test_done_time.append(diff + user_assessment_avg[-1]) # 마지막 문제는 현재 걸린 시간에 평균적으로 걸린 시간만큼만 더해줌\n","            user_assessment_avg.append(user_assessment_avg[-1]) # 마지막 문제는 이전의 평균 값으로 사용\n","\n","            pr_test_num, diff = 1, 0\n","            user_current_test = defaultdict(int)\n","            user_ox_count = dict()\n","            user_continue_ox_count = dict()\n","            user_assessmentnum_answerrate = dict()\n","        \n","        else: # 하나라도 끝내지 못한 시험지가 남아있다면\n","            diff += diff_time.total_seconds()\n","            user_test_done_time.append(diff)\n","            user_assessment_avg.append(diff/pr_test_num)\n","        \n","        pr_test_num += 1\n","    \n","    df = pd_join(df, \"userSolTime\", user_assessment_avg) # user의 문항을 푸는데 마친 평균 시간\n","    df = pd_join(df, \"userTestTime\", user_test_done_time) # user의 시험지 별 푸는데 마친 시간\n","    df = pd_join(df, \"userTestAnswer\", user_answer_cnt) # user의 시험지 별 정답 수\n","    df = pd_join(df, \"userTestWrong\", user_wrong_cnt) # user의 시험지 별 오답 수\n","    df = pd_join(df, \"userTestContAnswer\", user_continue_answer_cnt) # user의 시험지 별 연속 정답 수\n","    df = pd_join(df, \"userTestContWrong\", user_continue_wrong_cnt) # user의 시험지 별 연속 오답 수\n","    df = pd_join(df, \"userTestCorrectRate\", user_test_answer_rate) # user의 시험지 별 정답률\n","\n","    # 유저들의 문제 풀이수, 정답 수, 정답률을 시간순으로 누적해서 계산\n","    df['correctAnswer'] = df.groupby('userID')['answerCode'].transform(lambda x: x.cumsum().shift(1))\n","    df['correctAnswer'] = df['correctAnswer'].fillna(0)\n","    df['totalAnswer'] = df.groupby('userID')['answerCode'].cumcount()\n","    df['userAcc'] = df['correctAnswer']/df['totalAnswer']\n","    df['userAcc'] = df['userAcc'].fillna(0)\n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["# 결측치 채우기"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# 아라 feature 2개 결측치 채우기\n","def ara_fillna(df):\n","    df['userAcc'] = df['userAcc'].fillna(0)\n","    df['correctAnswer'] = df['correctAnswer'].fillna(0)\n","    return df\n","\n","# 내꺼 feature 4개 결측치 채우기\n","def mjh_fillna(df):\n","    df['user_total_correct_cnt'] = df['user_total_correct_cnt'].fillna(0)\n","    df['user_total_acc'] = df['user_total_acc'].fillna(0)\n","    df['user_test_correct_cnt_per_test'] = df['user_test_correct_cnt_per_test'].fillna(0)\n","    df['user_acc_per_test'] = df['user_acc_per_test'].fillna(0)\n","    return df"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["asset_dir = '/opt/p4-dkt-freshtomato/input/data/train_dataset/dict_for_feature'\n","# LB prediction에서 맞춰야하는 문항 ID 파악\n","def pd_join(data, column_name, value):\n","    value = pd.DataFrame(value, columns=[f\"{column_name}\"])\n","    data = data.join(value)\n","    return data\n","def save_pickle(path, values):\n","    os.makedirs(asset_dir, exist_ok=True)\n","    with open(f\"{asset_dir}/{path}\", 'wb') as f:\n","        pickle.dump(values, f)\n","\n","def load_pickle(path):\n","    with open(f\"{asset_dir}/{path}\", 'rb') as f:\n","        load_values = pickle.load(f)\n","    return load_values\n"]},{"cell_type":"markdown","metadata":{},"source":["# Feature Engineering"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["minyoung = False\n","\n","ara = False\n","ara_fillna_bool = False\n","\n","mjh_fillna_bool = False"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def feature_engineering(df, is_train):\n","    #############################################################################################\n","    start = time.time()  # 시작 시간 저장 \n","    #############################################################################################\n","\n","    if is_train:\n","        # 본 피쳐들은 train에서 얻어진 값을 그대로 유지합니다.\n","        testId_mean_sum_count = df.groupby(['testId'])['answerCode'].agg(['mean','sum','count']).to_dict()\n","        save_pickle(\"testId_mean_sum_count.pk\",testId_mean_sum_count)\n","\n","        assessmentItemID_mean_sum_count = df.groupby(['assessmentItemID'])['answerCode'].agg(['mean', 'sum','count']).to_dict()\n","        save_pickle(\"assessmentItemID_mean_sum_count.pk\",assessmentItemID_mean_sum_count)\n","\n","        KnowledgeTag_mean_sum_count = df.groupby(['KnowledgeTag'])['answerCode'].agg(['mean', 'sum','count']).to_dict()\n","        save_pickle(\"KnowledgeTag_mean_sum_count.pk\",KnowledgeTag_mean_sum_count)\n","\n","    # -> inference할 때는, 저장된 정답률을 가져와서 mapping하는 코드입니다.\n","    testId_mean_sum_count = load_pickle(\"testId_mean_sum_count.pk\")\n","    df[\"test_mean\"] = df.testId.map(testId_mean_sum_count['mean'])\n","    df['test_sum'] = df.testId.map(testId_mean_sum_count['sum'])\n","\n","    assessmentItemID_mean_sum_count = load_pickle(\"assessmentItemID_mean_sum_count.pk\")\n","    df[\"ItemID_mean\"] = df.assessmentItemID.map(assessmentItemID_mean_sum_count['mean'])\n","    df['ItemID_sum'] = df.assessmentItemID.map(assessmentItemID_mean_sum_count['sum'])\n","\n","    KnowledgeTag_mean_sum_count = load_pickle(\"KnowledgeTag_mean_sum_count.pk\")\n","    df[\"tag_mean\"] = df.KnowledgeTag.map(KnowledgeTag_mean_sum_count['mean'])\n","    df['tag_sum'] = df.KnowledgeTag.map(KnowledgeTag_mean_sum_count['sum'])\n","\n","    print(\"1번째 Time Lapse :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n","    \n","    #############################################################################################\n","    start = time.time()  # 시작 시간 저장 \n","    #############################################################################################\n","\n","    ## 문제번호 (시험지 내에서) (범주형? 연속형?) - 3자리\n","    # 0 부터 시작하도록 \n","    df['problem_number'] = df.assessmentItemID.map(lambda x: int(x[-3:])-1)\n","    if minyoung ==True:\n","        df = minyong_feature(df)\n","\n","    ## 시험지의(testID 별) 문제 최대개수가 몇인지 dict\n","    ## (이를 파악하여 중복 풀이하는 친구들을 걸러낼수있음)\n","    ## 0.37초 <- 아라가 짜준 코드는 1.4초\n","    total_num_prob_in_test = df[['assessmentItemID', 'testId']].drop_duplicates().groupby('testId').size()  \n","    testid_maxlen_dict = total_num_prob_in_test.to_dict()\n","    print(\"2번째 Time Lapse :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n","\n","    #############################################################################################\n","    start = time.time()  # 시작 시간 저장 \n","    #############################################################################################\n","    # 아라가 만들어준 피쳐들 추가\n","    if ara==True:\n","        df = ara_featunre(df)\n","    if ara_fillna_bool==True:\n","        df = ara_fillna(df)\n","    print(\"(3-1)번째 Time Lapse :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n","    #############################################################################################\n","    start = time.time()  # 시작 시간 저장 \n","    #############################################################################################\n","    df.Timestamp = pd.to_datetime(df.Timestamp)\n","    print(\"(3-2)번째 Time Lapse :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n","\n","    # 시험지별 문제번호의 최대값\n","    # 0.877초\n","    max_prob_in_test = df.groupby('testId').problem_number.max()\n","    # (시험지별 문제개수 != 시험지별 문제번호 최댓값)에 해당하는 시험지의 index를 추출한다. (양쪽다 Series를 이용)\n","    inconsistent_index = max_prob_in_test[max_prob_in_test +1 != total_num_prob_in_test].index  # max_prob_in_test는 0부터 시작하고, num_prob_in_test는 1부터 시작\n","    # 문제 max번호와 문제개수가 일치하지 않는 시험지에 해당하는 데이터프레임으로부터\n","    # (시험지 Id와 문제 Id) 추출 후 문제 Id 기준 오름차순 정렬\n","    inconsistent_df = df.loc[df.testId.isin(inconsistent_index),['assessmentItemID', 'testId']].drop_duplicates().sort_values('assessmentItemID')\n","\n","    # 순서대로 안 푼 시험지에서의 본래 문제의 순서가 dict에 저장된다 (inconsistent_Itemid_item_dict)\n","    inconsistent_Itemid_item_dict = {}\n","    inconsistent_df_group = inconsistent_df.groupby('testId')\n","    # 순서대로 안 푼 시험지들에 대하여 for문\n","    for key in inconsistent_df_group.groups:\n","        for i, (k,_) in enumerate(inconsistent_df_group.get_group(key).values):\n","            inconsistent_Itemid_item_dict[k] = i\n","\n","    #############################################################################################\n","    start = time.time()  # 시작 시간 저장 \n","    #############################################################################################\n","\n","    # origin_problem_order : 한 시험지 내에서 해당 문제 Id의 본래 순서 (중간에 비어있는 문제는 없는 문제로 생각하여 다시 순서를 매김)\n","    # ex) A080096003,A080096001,A080096005,A080096006,A080096007,A080096008,A080096002 \n","    # 문제번호 : 3, 1, 5, 6, 7, 8, 2 => 문제번호 중 4번이 빠져있음\n","    # 따라서 4번을 제외하고 문제번호를 본래순서에 대응시키면 => (1:0,2:1,3:2,5:3,6:4,7:5,8:6)\n","    # 변수생성 => origin_problem_order : (2,0,3,4,5,6,1)\n","    # 시험 문제번호의 최대값과 시험지 내의 문제개수가 일치하지 않는 시험지의 testId들을 추출        \n","    df['origin_problem_order'] =  df.assessmentItemID.map(lambda x: int(inconsistent_Itemid_item_dict[x]) if x in inconsistent_Itemid_item_dict else int(x[-3:]) - 1) # 0부터 시작하도록 -1 해줌.\n","    print(\"4번째 Time Lapse :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n","\n","    #############################################################################################\n","    start = time.time()  # 시작 시간 저장 \n","    #############################################################################################\n","    #유저별 시퀀스를 고려하기 위해 아래와 같이 정렬\n","    df.sort_values(by=['userID','Timestamp'], inplace=True)\n","    print(\"5번째 Time Lapse :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n","    \n","    #############################################################################################\n","    start = time.time()  # 시작 시간 저장 \n","    #############################################################################################\n","    # 유저가 푼 시험지들에 대해, 유저의 전체 정답/풀이횟수/정답률 계산\n","    df_group = df.groupby(['userID','testId'])['answerCode']\n","    print(\"(6-0)번째 Time Lapse :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n","\n","    #############################################################################################\n","    start = time.time()  # 시작 시간 저장 \n","    #############################################################################################\n","    df['user_total_correct_cnt'] = df_group.transform(lambda x: x.cumsum().shift(1))    # 정답개수\n","    print(\"(6-1)번째 Time Lapse :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n","\n","    #############################################################################################\n","    start = time.time()  # 시작 시간 저장 \n","    #############################################################################################\n","    df['user_total_ans_cnt'] = df_group.cumcount()  # 풀이횟수\n","    print(\"(6-2)번째 Time Lapse :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n","\n","    #############################################################################################\n","    start = time.time()  # 시작 시간 저장 \n","    #############################################################################################\n","    df['user_total_acc'] = df['user_total_correct_cnt'] / df['user_total_ans_cnt']  # 정답률\n","    print(\"(6-3)번째 Time Lapse :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n","\n","    #############################################################################################\n","    start = time.time()  # 시작 시간 저장 \n","    #############################################################################################\n","    # 유저가 풀고 있는 시험지에 대해, 현재 몇번째 문제인지\n","    df['total_num_prob_in_test'] = df.testId.map(testid_maxlen_dict)    # 문제수\n","    # 특정 시험지를 몇번째 반복하여 푸는지 계산\n","    df['nth_test'] = df['user_total_ans_cnt'] // df['total_num_prob_in_test'] # (같은)시험 완료 횟수\n","    df['user_test_ans_cnt'] = df['user_total_ans_cnt'] % df['total_num_prob_in_test']   # 현재 몇번째 문제인지\n","    print(\"7번째 Time Lapse :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n","\n","    # 각 시험지 당 유저의 정확도를 계산\n","    start = time.time()  # 시작 시간 저장 \n","    df['user_test_correct_cnt_per_test'] = df.groupby(['userID','testId','nth_test'])['answerCode'].transform(lambda x: x.cumsum().shift(1))\n","    print(\"(8-1)번째 Time Lapse :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n","    start = time.time()  # 시작 시간 저장 \n","    df['user_acc_per_test'] = df['user_test_correct_cnt_per_test']/df['user_test_ans_cnt']\n","    print(\"(8-2)번째 Time Lapse :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n","\n","    df['int_KnowledgeTag'] = df.KnowledgeTag.astype('int64')\n","    df['test_total_id'] = df['assessmentItemID'].map(lambda x: int(x[1:7]))\n","\n","    if mjh_fillna_bool==True:\n","        df = mjh_fillna(df)\n","    return df"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1번째 Time Lapse : 3.8865859508514404\n","2번째 Time Lapse : 3.2219443321228027\n","(3-1)번째 Time Lapse : 2.384185791015625e-06\n","(3-2)번째 Time Lapse : 1.123673677444458\n","4번째 Time Lapse : 2.451723098754883\n","5번째 Time Lapse : 3.3691723346710205\n","(6-0)번째 Time Lapse : 0.0013575553894042969\n","(6-1)번째 Time Lapse : 170.81101369857788\n","(6-2)번째 Time Lapse : 0.10434675216674805\n","(6-3)번째 Time Lapse : 0.01326608657836914\n","7번째 Time Lapse : 0.371859073638916\n","(8-1)번째 Time Lapse : 169.14058685302734\n","(8-2)번째 Time Lapse : 0.014133214950561523\n","1번째 Time Lapse : 0.1909785270690918\n","2번째 Time Lapse : 0.23412656784057617\n","(3-1)번째 Time Lapse : 2.384185791015625e-06\n","(3-2)번째 Time Lapse : 0.07741808891296387\n","4번째 Time Lapse : 0.18863272666931152\n","5번째 Time Lapse : 0.18066716194152832\n","(6-0)번째 Time Lapse : 0.0006699562072753906\n","(6-1)번째 Time Lapse : 18.373064517974854\n","(6-2)번째 Time Lapse : 0.009275436401367188\n","(6-3)번째 Time Lapse : 0.003023386001586914\n","7번째 Time Lapse : 0.03955554962158203\n","(8-1)번째 Time Lapse : 21.282508850097656\n","(8-2)번째 Time Lapse : 0.0020835399627685547\n"]}],"source":["df = feature_engineering(train, is_train=True)\n","df_test = feature_engineering(test, is_train=False)\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# def mjh_mean_fillna(df):\n","#     df['user_total_correct_cnt'] = df['user_total_correct_cnt'].fillna(df['user_total_correct_cnt'].mean())\n","#     df['user_total_acc'] = df['user_total_acc'].fillna(df['user_total_acc'].mean())\n","#     df['user_test_correct_cnt_per_test'] = df['user_test_correct_cnt_per_test'].fillna(df['user_test_correct_cnt_per_test'].mean())\n","#     df['user_acc_per_test'] = df['user_acc_per_test'].fillna(df['user_acc_per_test'].mean())\n","#     return df\n","# df = mjh_mean_fillna(df)\n","# df_test = mjh_mean_fillna(df_test)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["df.shape : (2266586, 24)\n","df_test.shape : (260114, 24)\n"]}],"source":["print(f'df.shape : {df.shape}')\n","print(f\"df_test.shape : {df_test.shape}\")"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"jjt90EavVzji"},"outputs":[{"name":"stdout","output_type":"stream","text":["df_csv_name_after_FE : /opt/p4-dkt-freshtomato/input/data/train_dataset/df_피쳐내꺼만_24개_결측치그대로놔둠.csv\n"]}],"source":["df_csv_name_after_FE = f'{upper_dir}/df_피쳐내꺼만_24개_결측치그대로놔둠.csv'\n","df.to_csv(df_csv_name_after_FE,index=False)\n","# df = pd.read_csv(df_csv_name_after_FE)\n","print(f\"df_csv_name_after_FE : {df_csv_name_after_FE}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":399,"status":"ok","timestamp":1622563911840,"user":{"displayName":"문재훈","photoUrl":"","userId":"02977204597809886794"},"user_tz":-540},"id":"qP3LS8_PU1vH","outputId":"7de71b0b-758a-4a51-a3be-dd59f5a118e7"},"outputs":[{"data":{"text/plain":"(2266586, 24)"},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"V1Ct8LUX-shj"},"outputs":[],"source":["df_test_shift = df_test[df_test['userID'] != df_test['userID'].shift(-1)]"]},{"cell_type":"markdown","metadata":{"id":"wFLTDadShGYT"},"source":["## 엔지니어링 이후의 EDA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137,"referenced_widgets":["f721ab5cdd524830861948c508b02cf5","3cd74ccffbf242c0afa2232bfa85ed06","f14b908c6a864e8ea051b15e61095076","c29715ad8e3349a79c20678dd0468562","f494c699f88d4576bc6b988bb2044920","ed101556176343888bcd898dc17ff9e6","ccc9698663bf43868b76712e454229fb","1f595e8f870a4edfb9642dd1456d1c15"]},"executionInfo":{"elapsed":66142,"status":"ok","timestamp":1622573644569,"user":{"displayName":"문재훈","photoUrl":"","userId":"02977204597809886794"},"user_tz":-540},"id":"v5zP7xp3Y1JZ","outputId":"8fa789a4-af82-4fba-ea2a-fa8e5689ff84"},"outputs":[],"source":["# 생성된 Feature 잘못된거 없는지 확인\n","# c = 'test_mean'\n","# print(df.groupby(['userID']).apply(lambda x: x.iloc[-1])[c].isnull().sum())\n","# df.groupby(['userID']).apply(lambda x: x.iloc[-1])[c].value_counts()\n","\n","# print(df_test.groupby(['userID']).apply(lambda x: x.iloc[-1])[c].isnull().sum())\n","# df_test.groupby(['userID']).apply(lambda x: x.iloc[-1])[c].value_counts()\n","\n","num_nan_column_train = {}\n","num_nan_column_test = {}\n","from tqdm import tqdm_notebook\n","for c in tqdm_notebook(df.columns):\n","    nan_count = df.groupby(['userID']).apply(lambda x: x.iloc[-1])[c].isnull().sum()\n","    if nan_count!=0:\n","        num_nan_column_train[c] = nan_count\n","    nan_count = df_test.groupby(['userID']).apply(lambda x: x.iloc[-1])[c].isnull().sum()\n","    if nan_count!=0:\n","        num_nan_column_test[c] = nan_count\n","\n","# 각 User별 마지막 행에 결측치가 있는지 조사하는 코드 (마지막 행 결측치 존재할 때, column이 출력됨)\n","print('User 별 마지막 row에 결측치가 존재하는 경우')\n","print(len(num_nan_column_train))\n","print(len(num_nan_column_test))\n","print(num_nan_column_train)\n","print(num_nan_column_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_nan_column_train = {}\n","num_nan_column_test = {}\n","from tqdm import tqdm_notebook\n","for c in tqdm_notebook(df.columns):\n","    nan_count = df.groupby(['userID']).apply(lambda x: x.iloc[0])[c].isnull().sum()\n","    if nan_count!=0:\n","        num_nan_column_train[c] = nan_count\n","    nan_count = df_test.groupby(['userID']).apply(lambda x: x.iloc[0])[c].isnull().sum()\n","    if nan_count!=0:\n","        num_nan_column_test[c] = nan_count\n","\n","# 각 User별 첫 행에 결측치가 있는지 조사하는 코드 (첫 행 결측치 존재할 때, column이 출력됨)\n","print('User 별 첫 row에 결측치가 존재하는 경우')\n","print(len(num_nan_column_train))\n","print(len(num_nan_column_test))\n","print(num_nan_column_train)\n","print(num_nan_column_test)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":327,"status":"ok","timestamp":1622574217308,"user":{"displayName":"문재훈","photoUrl":"","userId":"02977204597809886794"},"user_tz":-540},"id":"9_rR_FGG9T5u","outputId":"2599f13f-2a18-49bf-8d40-33cb846e41fb"},"outputs":[{"data":{"text/plain":"{'user_total_correct_cnt': 365164,\n 'user_total_acc': 365164,\n 'user_test_correct_cnt_per_test': 372603,\n 'user_acc_per_test': 372603}"},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["# 모든 데이터셋에 대하여 결측치가 1개 이상인 column, 결측치 개수\n","{k:v for k,v in df.isnull().sum().to_dict().items() if v!=0}"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# # 아라 feature 2개 결측치 채우기\n","# def ara_fillna(df):\n","#     df['userAcc'] = df['userAcc'].fillna(0)\n","#     df['correctAnswer'] = df['correctAnswer'].fillna(0)\n","#     return df\n","\n","# # 내꺼 feature 4개 결측치 채우기\n","# def mjh_fillna(df):\n","#     df['user_total_correct_cnt'] = df['user_total_correct_cnt'].fillna(0)\n","#     df['user_total_acc'] = df['user_total_acc'].fillna(0)\n","#     df['user_test_correct_cnt_per_test'] = df['user_test_correct_cnt_per_test'].fillna(0)\n","#     df['user_acc_per_test'] = df['user_acc_per_test'].fillna(0)\n","#     return df"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1622574126793,"user":{"displayName":"문재훈","photoUrl":"","userId":"02977204597809886794"},"user_tz":-540},"id":"gpJ4WYce8w_I","outputId":"b8fc2fe9-ae63-4be4-d5d8-f74e868bd3f0"},"outputs":[{"data":{"text/plain":"1.0     507090\n2.0     420585\n3.0     331972\n0.0     247793\n4.0     221177\n5.0      97507\n6.0      44513\n7.0      15374\n8.0       4740\n9.0       1896\n10.0       891\n11.0       392\n12.0        53\nName: user_test_correct_cnt_per_test, dtype: int64"},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["df.user_test_correct_cnt_per_test.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"FloWAa2IFGRy"},"source":["# Split Train valid Set"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["is_all_data = False\n","valid_only_LB = 'problem'   # '', 'test' # prediction에 사용할 test row들의 (문제ID, 시험지ID)에 해당하는 row만 추출하여 Valid한다.\n","train_except_holdout = False   # 'index', 'user' # holdout과 train을 겹치지 않게 할지, 그렇다면 그 기준은 무엇으로 할지\n","train_only_LB = False   # 'problem', 'test' # prediction에 사용할 test row들의 (문제ID, 시험지ID)에 해당하는 row만 추출하여 Train한다.\n","train_with_finalrow = 'test'  # None 'test','user' # 시험지 혹은 유저별 마지막 row만 가져와서 학습할 것인지\n","seed = 47\n"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"1cvgUhyvMO12"},"outputs":[],"source":["def train_holdout_split(\n","                        df, \n","                        is_all_data=is_all_data,  # input df가 train과 test 모두인지,\n","                        valid_only_LB=valid_only_LB,\n","                        train_except_holdout=train_except_holdout,\n","                        train_with_finalrow = train_with_finalrow,\n","                        train_only_LB = train_only_LB,\n","                        ):\n","\n","    # 모두 train으로 사용한다면 answerCode==-1에 해당하는 row는 모두 지워준다.\n","    if is_all_data:\n","        copy_df = df[df.answerCode != -1].copy()\n","    else:\n","        copy_df = df.copy()\n","\n","    # 유저별 마지막 row에 해당하는 데이터만 Holdout으로 사용\n","    # 추가적으로 LB Test set과 동일 조건의 row만 Valid에서 추출할지 결정\n","    if valid_only_LB=='':\n","        holdout = df[(df['userID'] != df['userID'].shift(-1))].copy()\n","    # True라면, 추가조건으로 리더보드와 동일 문제ID에 해당하는 row만 추출하여 holdout로 사용\n","    elif valid_only_LB=='problem':\n","        holdout = df[(df['userID'] != df['userID'].shift(-1)) & (df.assessmentItemID.isin(set_assessmentItemID))].copy()\n","    # True라면, 추가조건으로 리더보드와 동일 시험ID에 해당하는 row만 추출하여 holdout로 사용\n","    elif valid_only_LB=='test':\n","        holdout = df[(df['userID'] != df['userID'].shift(-1)) & (df.testId.isin(set_testID))].copy()\n","\n","    print(f\"set(holdout.userID) : {len(set(holdout.userID))}\")\n","    print(f\"set(holdout.index) : {len(set(holdout.index))}\")\n","    if train_except_holdout=='user':\n","        tr_val = copy_df[ copy_df['userID'].isin(set(holdout.userID)) == False ].copy()\n","    elif train_except_holdout=='index':\n","        tr_val = copy_df[ copy_df.index.isin(set(holdout.index)) == False ].copy()\n","    else:\n","        tr_val = copy_df.copy()\n","    print(f\"(tr_val.shape) : {tr_val.shape}\")\n","\n","    # 학습시 무엇을 기준으로 마지막 row만 가져올지\n","    if train_with_finalrow == 'test':\n","        tr_val = tr_val[tr_val['testId'] != tr_val['testId'].shift(-1)].copy()\n","    elif train_with_finalrow == 'user':\n","        tr_val = tr_val[tr_val['userID'] != tr_val['userID'].shift(-1)].copy()\n","    else:\n","        pass\n","\n","    # LB prediction의 row에서 맞혀야하는 문제들만 학습할 것인지 (444개)\n","    if train_only_LB=='problem':\n","        tr_val = tr_val[tr_val.assessmentItemID.isin(set_assessmentItemID)].copy()\n","    # LB prediction의 row에서 맞혀야하는 시험지들만 학습할 것인지 (411개)\n","    elif train_only_LB=='test':\n","        tr_val = tr_val[tr_val.testId.isin(set_testID)].copy()\n","    else:\n","        pass\n","\n","    return tr_val, holdout"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["set(holdout.userID) : 4366\n","set(holdout.index) : 4366\n","(tr_val.shape) : (2266586, 24)\n","374594 4366\n","0.5601958386946935 0.48259276225377923\n"]}],"source":["seed = 47\n","fold = 10\n","method = 'soft' # 'soft' , 'hard' : 모델들 blend할 때, 앙상블방법\n","\n","\n","\n","tr_val, holdout = train_holdout_split(\n","                                    df, \n","                                    is_all_data=is_all_data,\n","                                    valid_only_LB=valid_only_LB,\n","                                    train_except_holdout=train_except_holdout,\n","                                    train_with_finalrow = train_with_finalrow,\n","                                    train_only_LB = train_only_LB,\n","                                    )\n","print(len(tr_val), len(holdout))\n","print(tr_val.answerCode.mean(), holdout.answerCode.mean())\n"]},{"cell_type":"markdown","metadata":{"id":"npqAI40BIMnK"},"source":["# AUTOML (NGBoosting도 쓸 수 있으니 참고)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["## scikit-learn 기반 모델이면 다음과 같이 다 써볼수가 있음.\n","from ngboost import NGBClassifier\n","# ngc = NGBClassifier()\n","# ngboost = create_model(ngc)\n","\n","model_name_list=[\"lightgbm\"]   # lightgbm, gbc, lda, catboost, et, ada, rf, lr, nb, knn, qda, dt, xgboost, ngboost\n","ensemble_method = 'blend_models'  # 'blend_models', 'stack_models' # (Classifier : 'stack_models'), (Regression : 'create_stacknet')\n","meta_model_for_stack = 'xgboost' # If using stack_models"]},{"cell_type":"markdown","metadata":{},"source":["## 모델, grid score df, plot, config, output csv 파일들이 저장될 상위 경로"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["upper_dir_of_pycaret : /opt/p4-dkt-freshtomato/output_pycaret/0603_0818\n"]}],"source":["# 모델들, grid score df, plot 등이 모두 저장되는 상위경로\n","now_time = datetime.now(timezone(timedelta(hours=9))).strftime('%m%d_%H%M')\n","upper_dir_of_pycaret = f'/opt/p4-dkt-freshtomato/output_pycaret/{now_time}'\n","print(f\"upper_dir_of_pycaret : {upper_dir_of_pycaret}\")"]},{"cell_type":"markdown","metadata":{},"source":["##  각 단계마다 (create - tune - ensemble - finalize) 모델, 정보 저장해주는 코드"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["def plot_save_pycaret_model(name, model,mode='tune'):\n","    # Feature Importance Plot 저장하기\n","    plot_dir = f'{upper_dir_of_pycaret}/plot_result'\n","    os.makedirs(plot_dir, exist_ok=True)\n","    os.chdir(plot_dir)\n","    # top10 feature\n","    feature_importance_plot = plot_model(model, plot = 'feature', save=True)\n","    os.rename(f'{plot_dir}/Feature Importance.png',f'{plot_dir}/{mode}_{name}_10_feature_importance.png')\n","    # all feature\n","    feature_importance_plot = plot_model(model, plot = 'feature_all', save=True)\n","    os.rename(f'{plot_dir}/Feature Importance (All).png',f'{plot_dir}/{mode}_{name}_all_feature_importance.png')\n","\n","# def create_and_save_pycaret_model(name):\n","#     created_model = create_model(name, cross_validation = True)\n","#     # Display되는 score grid dataframe도 가져올 수가 있다. \n","#     df_result_model = pull()\n","#     df_result_model.to_csv(f'{upper_dir_of_pycaret}/{name}_create_grid_df.csv')\n","#     # 실험결과를 저장하는 것도 가능하다.\n","#     save_experiment(f'{upper_dir_of_pycaret}/{name}_create_exp_result')\n","#     # 모델을 저장하는 것도 가능하다.\n","#     save_model(created_model, f'{upper_dir_of_pycaret}/{name}_model_saved')\n","#     return created_model\n","\n","def tune_and_save_pycaret_model(name, model, optimize = 'AUC', fold = fold, n_iter = 10):\n","    tuned_model = tune_model(model, optimize = optimize, fold = fold, n_iter = n_iter)\n","    # Display되는 score grid dataframe도 가져올 수가 있다. \n","    df_result_model = pull()\n","    os.makedirs(f\"{upper_dir_of_pycaret}/grid_df\",exist_ok=True)\n","    df_result_model.to_csv(f'{upper_dir_of_pycaret}/grid_df/{name}_tuned_grid_df.csv')\n","    # 모델의 각종 plot을 저장하는 것도 가능하다.\n","    plot_save_pycaret_model(name, tuned_model, mode='tune')\n","    # 실험결과를 저장하는 것도 가능하다.\n","    os.makedirs(f\"{upper_dir_of_pycaret}/expr\",exist_ok=True)\n","    try:\n","        save_experiment(f'{upper_dir_of_pycaret}/expr/{name}_tuned_exp_result')\n","    except:\n","        print('tuned model의 실험결과는 저장할 수 없습니다.')\n","    # 모델을 저장하는 것도 가능하다.\n","    os.makedirs(f\"{upper_dir_of_pycaret}/models\",exist_ok=True)\n","    save_model(tuned_model, f'{upper_dir_of_pycaret}/models/{name}_tuned_model_saved')\n","    return tuned_model\n","\n","def ensemble_and_save_pycaret_model(\n","                                    model_name_list,\n","                                    estimator_list,\n","                                    fold = fold,\n","                                    optimize = 'AUC',\n","                                    method = method,\n","                                    meta_model = meta_model_for_stack,\n","                                    mode = ensemble_method,\n","                                    ):\n","    print('Now Ensemble the models....')\n","    if mode=='blend_models':\n","        ensembled_model = blend_models(estimator_list = estimator_list, fold = fold, optimize = optimize, method = method)\n","    elif mode=='stack_models':\n","        ensembled_model = stack_models(estimator_list = estimator_list, fold = fold, optimize = optimize, meta_model = meta_model)\n","    # Display되는 score grid dataframe도 가져올 수가 있다. \n","    df_result_model = pull()\n","    name = '_'.join(model_name_list)\n","    os.makedirs(f\"{upper_dir_of_pycaret}/grid_df\",exist_ok=True)\n","    df_result_model.to_csv(f'{upper_dir_of_pycaret}/grid_df/{name}_ensembled_grid_df.csv')\n","    # 모델의 각종 plot을 저장하는 것도 가능하다.\n","    try:\n","        plot_save_pycaret_model(name, ensembled_model, mode='tune')\n","    except:\n","        print(f'ensemble model은 변수중요도 plot을 저장할 수 없습니다')\n","    # 실험결과를 저장하는 것도 가능하다.\n","    os.makedirs(f\"{upper_dir_of_pycaret}/expr\",exist_ok=True)\n","    try:\n","        save_experiment(f'{upper_dir_of_pycaret}/expr/{name}_ensembled_exp_result')\n","    except:\n","        print(f'ensemble model은 실험결과를 저장할 수 없습니다')\n","    # 모델을 저장하는 것도 가능하다.\n","    os.makedirs(f\"{upper_dir_of_pycaret}/models\",exist_ok=True)\n","    save_model(ensembled_model, f'{upper_dir_of_pycaret}/models/{name}_ensembled_model_saved')\n","    return ensembled_model\n","\n","\n","def finalize_and_save_pycaret_model(model_name_list,model,):\n","    print('Now Finalizing the model....')\n","    finalized_model = finalize_model(model)\n","    # Display되는 score grid dataframe도 가져올 수가 있다. \n","    df_result_model = pull()\n","    name = '_'.join(model_name_list)\n","    os.makedirs(f\"{upper_dir_of_pycaret}/grid_df\",exist_ok=True)\n","    df_result_model.to_csv(f'{upper_dir_of_pycaret}/grid_df/{name}_finalized_grid_df.csv')\n","    # 모델의 각종 plot을 저장하는 것도 가능하다.\n","    try:\n","        plot_save_pycaret_model(name, finalized_model, mode='tune')\n","    except:\n","        print(f'final model은 변수중요도 plot을 저장할 수 없습니다')\n","    # 실험결과를 저장하는 것도 가능하다.\n","    os.makedirs(f\"{upper_dir_of_pycaret}/expr\",exist_ok=True)\n","    try:\n","        save_experiment(f'{upper_dir_of_pycaret}/expr/{name}_finalized_exp_result')\n","    except:\n","        print(f'final model은 실험결과를 저장할 수 없습니다')\n","    # 모델을 저장하는 것도 가능하다.\n","    os.makedirs(f\"{upper_dir_of_pycaret}/models\",exist_ok=True)\n","    save_model(finalized_model, f'{upper_dir_of_pycaret}/models/{name}_finalized_model_saved')\n","    return finalized_model\n"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["# setup(data=tr_val[FEATS], target='answerCode', train_size=0.8, categorical_features=cat_features, numeric_features=continuous_features)\n","# created_model = create_model('dt', cross_validation = True)\n","# df_results = pull()\n","\n","# os.makedirs(upper_dir_of_pycaret,exist_ok=True)\n","# df_results.to_csv(f'{upper_dir_of_pycaret}/df_results.csv')\n","# pd.read_csv(f'{upper_dir_of_pycaret}/name_ensembled_grid_df.csv',index_col=0)\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp',\n","       'KnowledgeTag', 'test_mean', 'test_sum', 'ItemID_mean', 'ItemID_sum',\n","       'tag_mean', 'tag_sum', 'problem_number', 'origin_problem_order',\n","       'user_total_correct_cnt', 'user_total_ans_cnt', 'user_total_acc',\n","       'total_num_prob_in_test', 'nth_test', 'user_test_ans_cnt',\n","       'user_test_correct_cnt_per_test', 'user_acc_per_test',\n","       'int_KnowledgeTag', 'test_total_id'],\n","      dtype='object')\n"]}],"source":["print(df.columns) # FEATS 참고용"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["FEATS : 21\n","target : 'answerCode'\n","cat_features : 6\n","continuous_features : 13\n","etc_features : ['Timestamp']\n"]}],"source":["experiment_name = 'USEFEAT-mjh-only_NOT-FILLNA'\n","FEATS = [c for c in df.columns if c not in ['userID', 'assessmentItemID', 'testId', 'diff']]\n","\n","cat_features = ['problem_number','origin_problem_order',\n","              'total_num_prob_in_test','nth_test',\n","              'user_test_ans_cnt','user_test_correct_cnt_per_test']\n","\n","continuous_features = [f for f in FEATS if f not in cat_features+['answerCode','Timestamp','diff']]\n","\n","# continuous_features += []\n","\n","print(f'FEATS : {len(FEATS)}')\n","print(f\"target : 'answerCode'\")\n","print(f'cat_features : {len(cat_features)}')\n","print(f'continuous_features : {len(continuous_features)}')\n","print(f\"etc_features : {[f for f in FEATS if f not in cat_features+continuous_features+['answerCode']]}\")\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["def ensemble_automl(\n","                    tr_val,\n","                    holdout,\n","                    FEATS,\n","                    cat_features=[],\n","                    continuous_features=[],\n","                    seed=seed,\n","                    model_name_list=model_name_list,\n","                    ensemble_method = ensemble_method,\n","                    meta_model_for_stack = meta_model_for_stack,\n","                    ):\n","\n","    # tr_val, holdout = datasets\n","    random.seed(seed)\n","    settings = setup(\n","                    data=tr_val[FEATS], \n","                    target='answerCode', \n","                    train_size=0.8, \n","                    categorical_features=cat_features, \n","                    numeric_features=continuous_features,\n","                    # log_experiment=False,   # compare_model 할 때에는 하이퍼파라미터가 어떻게 튜닝되었는지 볼 수 있어서 유용하다고 한다.\n","                    experiment_name=experiment_name,\n","                    )\n","\n","    # train_size만큼을 가지고 선언된 model_name_list 모델들을 학습을 함\n","    # create_model(name, sort='AUC', cross_validation = True)\n","    models_before_tune = [create_model(name, cross_validation = True) for name in model_name_list]\n","    # 앞서만든 모델들을 train_size만큼 가지고 튜닝함 (n_iter만큼 AutoML)\n","    # models_after_tune = [tune_model(model, optimize = 'AUC', fold = 10, n_iter = 10) for model in models_before_tune]\n","    models_after_tune = [tune_and_save_pycaret_model(name, model, optimize = 'AUC', fold = 10, n_iter = 10) for name, model in zip(model_name_list, models_before_tune)]\n","\n","\n","    # 튜닝된 모델들을 train_size만큼 가지고 앙상블\n","    if len(models_after_tune)<=1:\n","        ensembled = models_after_tune[0]\n","    else:\n","        ensembled = ensemble_and_save_pycaret_model(model_name_list,estimator_list=models_after_tune,fold = fold,optimize = 'AUC',method = method,meta_model = meta_model_for_stack,mode = ensemble_method)\n","    # elif ensemble_method=='blend_models':\n","    #     ensembled = blend_models(estimator_list = models_after_tune, fold = 10, method = 'soft', optimize = 'AUC')\n","    # elif ensemble_method=='stack_models':\n","    #     ensembled = stack_models(estimator_list = models_after_tune, meta_model = meta_model_for_stack, fold = 10, optimize = 'AUC')\n","\n","    # 마지막 학습(Finalize)\n","    # 앞서 앙상블된 모델을 => setup으로 나눠져 쓰지않았던 valid까지 포함된 100퍼센트를 사용하여 fitting함\n","    final_model = finalize_and_save_pycaret_model(model_name_list,ensembled)\n","\n","    metric_result = []\n","    prediction = predict_model(final_model, data=holdout[FEATS], raw_score = True)\n","    df_holdout_score = pull()\n","\n","    os.makedirs(f\"{upper_dir_of_pycaret}/holdout_score\",exist_ok=True)\n","    df_holdout_score.to_csv(f'{upper_dir_of_pycaret}/holdout_score/finalize_holdout_score.csv')\n","\n","    metric_result.append(f\"HoldOut 데이터 ACC & AUC: {check_metric(prediction['answerCode'], prediction['Label'], metric = 'Accuracy')} ,{check_metric(prediction['answerCode'], prediction['Score_1'], metric = 'AUC')}\")\n","    return final_model, metric_result"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["final model은 실험결과를 저장할 수 없습니다\n","Transformation Pipeline and Model Succesfully Saved\n","LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',\n","               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,\n","               importance_type='split', learning_rate=0.3, max_depth=-1,\n","               min_child_samples=46, min_child_weight=0.001, min_split_gain=0.3,\n","               n_estimators=190, n_jobs=-1, num_leaves=20, objective=None,\n","               random_state=5914, reg_alpha=3, reg_lambda=0.0005, silent=True,\n","               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n","ACC & AUC :  HoldOut 데이터 ACC & AUC: 0.741 ,0.8198\n"]}],"source":["final_model, metric_result = ensemble_automl(\n","                                            tr_val,\n","                                            holdout,\n","                                            FEATS,\n","                                            cat_features,\n","                                            continuous_features,\n","                                            seed=seed,\n","                                            model_name_list=model_name_list,\n","                                            ensemble_method = ensemble_method,\n","                                            meta_model_for_stack = meta_model_for_stack,\n","                                            )\n","\n","print(final_model)\n","\n","print(f\"ACC & AUC : \",'\\n'.join(metric_result))"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e18d7d2451a34144adae5b1425053ba6","version_major":2,"version_minor":0},"text/plain":"  0%|          | 0/24 [00:00<?, ?it/s]"},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"{'userID': 6698,\n 'assessmentItemID': 9454,\n 'testId': 1537,\n 'answerCode': 2,\n 'Timestamp': 2076774,\n 'KnowledgeTag': 912,\n 'test_mean': 1495,\n 'test_sum': 850,\n 'ItemID_mean': 5274,\n 'ItemID_sum': 306,\n 'tag_mean': 908,\n 'tag_sum': 798,\n 'problem_number': 13,\n 'origin_problem_order': 13,\n 'user_total_correct_cnt': 24,\n 'user_total_ans_cnt': 27,\n 'user_total_acc': 181,\n 'total_num_prob_in_test': 12,\n 'nth_test': 3,\n 'user_test_ans_cnt': 13,\n 'user_test_correct_cnt_per_test': 13,\n 'user_acc_per_test': 47,\n 'int_KnowledgeTag': 912,\n 'test_total_id': 1537}"},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["num_category_per_feature = {}\n","for c in tqdm_notebook(df.columns):\n","    num_category_per_feature[c] = len(df[c].value_counts())\n","num_category_per_feature"]},{"cell_type":"markdown","metadata":{"id":"3TLSfyOuFGR0"},"source":["\n","\n","# Inference"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["config_key = [\n","            'experiment_name','is_all_data','valid_only_LB','train_except_holdout','train_only_LB','train_with_finalrow',\n","            'seed','fold','method','model_name_list','ensemble_method','meta_model_for_stack',\n","            'cat_features','continuous_features','FEATS'\n","            ]\n","config_value = [\n","                experiment_name,is_all_data,valid_only_LB,train_except_holdout,train_only_LB,train_with_finalrow,\n","                seed,fold,method,model_name_list,ensemble_method,meta_model_for_stack,\n","                cat_features,continuous_features,FEATS]\n"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":523,"status":"ok","timestamp":1622561479133,"user":{"displayName":"문재훈","photoUrl":"","userId":"02977204597809886794"},"user_tz":-540},"id":"6mHls0urFGR3","outputId":"a3d84cf6-0e11-4a02-9919-dafc022ecbc3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving Final Output Csv...\n","writing prediction : /opt/p4-dkt-freshtomato/output_pycaret/0603_0818/submission/피쳐21개사용_USEFEAT-mjh-only_NOT-FILLNA.csv\n","Saving Final Config Dict...\n","writing config : /opt/p4-dkt-freshtomato/output_pycaret/0603_0818/submission/피쳐21개사용_USEFEAT-mjh-only_NOT-FILLNA_config.json\n"]}],"source":["# MAKE PREDICTION\n","prediction = predict_model(final_model, data=df_test_shift[FEATS], raw_score=True)\n","total_preds = prediction.Score_1.values\n","\n","# SAVE OUTPUT\n","prediction_name = f\"피쳐{len(FEATS)}개사용_{experiment_name}\" # \n","\n","output_dir = f'{upper_dir_of_pycaret}/submission'\n","os.makedirs(output_dir, exist_ok=True)    \n","write_path = os.path.join(output_dir, f\"{prediction_name}.csv\")\n","print(\"Saving Final Output Csv...\")\n","with open(write_path, 'w', encoding='utf8') as w:\n","    print(f\"writing prediction : {write_path}\")\n","    w.write(\"id,prediction\\n\")\n","    for id, p in enumerate(total_preds):\n","        w.write('{},{}\\n'.format(id,p))\n","\n","# Save Config\n","write_path = os.path.join(output_dir, f\"{prediction_name}_config.json\")\n","config_dict = {k:v for k,v in zip(config_key, config_value)}\n","print(\"Saving Final Config Dict...\")\n","## json파일 저장 ##\n","with open(write_path, \"w\") as fp:\n","    print(f\"writing config : {write_path}\")\n","    json.dump(config_dict, fp, indent=4)"]},{"cell_type":"markdown","metadata":{},"source":["# 저장된 결과들 로드해오기"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # load 해오는방법\n","\n","## Loading Saved Model\n","# dt_saved = load_model('dt_saved_07032020')\n","\n","# # Loading saved experiment\n","# experiment_saved = load_experiment('experiment_07032020')\n","\n","# # Loading Saved grid score df\n","# name_tuned_grid_df = pd.read_csv(f'{upper_dir_of_pycaret}/name_tuned_grid_df.csv',index_col=0)"]},{"cell_type":"markdown","metadata":{},"source":["## get_logs function 연습해보기\n","\n","It returns the logs for active experiment when log_experiment in setup is set as True. To retrieve logs for inactive experiment, use experiment_name parameter with get_logs. To save csv file locally, set save parameter as True.\n","\n"]},{"cell_type":"code","execution_count":108,"metadata":{"id":"62fN1Q-7aPIx"},"outputs":[{"data":{"text/html":"<style  type=\"text/css\" >\n#T_3fb0a_row19_col1{\n            background-color:  lightgreen;\n        }</style><table id=\"T_3fb0a_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Description</th>        <th class=\"col_heading level0 col1\" >Value</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_3fb0a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_3fb0a_row0_col0\" class=\"data row0 col0\" >session_id</td>\n                        <td id=\"T_3fb0a_row0_col1\" class=\"data row0 col1\" >559</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n                        <td id=\"T_3fb0a_row1_col0\" class=\"data row1 col0\" >Target</td>\n                        <td id=\"T_3fb0a_row1_col1\" class=\"data row1 col1\" >Class variable</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n                        <td id=\"T_3fb0a_row2_col0\" class=\"data row2 col0\" >Target Type</td>\n                        <td id=\"T_3fb0a_row2_col1\" class=\"data row2 col1\" >Binary</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n                        <td id=\"T_3fb0a_row3_col0\" class=\"data row3 col0\" >Label Encoded</td>\n                        <td id=\"T_3fb0a_row3_col1\" class=\"data row3 col1\" >0: 0, 1: 1</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n                        <td id=\"T_3fb0a_row4_col0\" class=\"data row4 col0\" >Original Data</td>\n                        <td id=\"T_3fb0a_row4_col1\" class=\"data row4 col1\" >(768, 9)</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n                        <td id=\"T_3fb0a_row5_col0\" class=\"data row5 col0\" >Missing Values</td>\n                        <td id=\"T_3fb0a_row5_col1\" class=\"data row5 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n                        <td id=\"T_3fb0a_row6_col0\" class=\"data row6 col0\" >Numeric Features</td>\n                        <td id=\"T_3fb0a_row6_col1\" class=\"data row6 col1\" >7</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n                        <td id=\"T_3fb0a_row7_col0\" class=\"data row7 col0\" >Categorical Features</td>\n                        <td id=\"T_3fb0a_row7_col1\" class=\"data row7 col1\" >1</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n                        <td id=\"T_3fb0a_row8_col0\" class=\"data row8 col0\" >Ordinal Features</td>\n                        <td id=\"T_3fb0a_row8_col1\" class=\"data row8 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n                        <td id=\"T_3fb0a_row9_col0\" class=\"data row9 col0\" >High Cardinality Features</td>\n                        <td id=\"T_3fb0a_row9_col1\" class=\"data row9 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n                        <td id=\"T_3fb0a_row10_col0\" class=\"data row10 col0\" >High Cardinality Method</td>\n                        <td id=\"T_3fb0a_row10_col1\" class=\"data row10 col1\" >None</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n                        <td id=\"T_3fb0a_row11_col0\" class=\"data row11 col0\" >Transformed Train Set</td>\n                        <td id=\"T_3fb0a_row11_col1\" class=\"data row11 col1\" >(537, 23)</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n                        <td id=\"T_3fb0a_row12_col0\" class=\"data row12 col0\" >Transformed Test Set</td>\n                        <td id=\"T_3fb0a_row12_col1\" class=\"data row12 col1\" >(231, 23)</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n                        <td id=\"T_3fb0a_row13_col0\" class=\"data row13 col0\" >Shuffle Train-Test</td>\n                        <td id=\"T_3fb0a_row13_col1\" class=\"data row13 col1\" >True</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n                        <td id=\"T_3fb0a_row14_col0\" class=\"data row14 col0\" >Stratify Train-Test</td>\n                        <td id=\"T_3fb0a_row14_col1\" class=\"data row14 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n                        <td id=\"T_3fb0a_row15_col0\" class=\"data row15 col0\" >Fold Generator</td>\n                        <td id=\"T_3fb0a_row15_col1\" class=\"data row15 col1\" >StratifiedKFold</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n                        <td id=\"T_3fb0a_row16_col0\" class=\"data row16 col0\" >Fold Number</td>\n                        <td id=\"T_3fb0a_row16_col1\" class=\"data row16 col1\" >10</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n                        <td id=\"T_3fb0a_row17_col0\" class=\"data row17 col0\" >CPU Jobs</td>\n                        <td id=\"T_3fb0a_row17_col1\" class=\"data row17 col1\" >-1</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n                        <td id=\"T_3fb0a_row18_col0\" class=\"data row18 col0\" >Use GPU</td>\n                        <td id=\"T_3fb0a_row18_col1\" class=\"data row18 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n                        <td id=\"T_3fb0a_row19_col0\" class=\"data row19 col0\" >Log Experiment</td>\n                        <td id=\"T_3fb0a_row19_col1\" class=\"data row19 col1\" >True</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n                        <td id=\"T_3fb0a_row20_col0\" class=\"data row20 col0\" >Experiment Name</td>\n                        <td id=\"T_3fb0a_row20_col1\" class=\"data row20 col1\" >diabetes1</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n                        <td id=\"T_3fb0a_row21_col0\" class=\"data row21 col0\" >USI</td>\n                        <td id=\"T_3fb0a_row21_col1\" class=\"data row21 col1\" >21ab</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n                        <td id=\"T_3fb0a_row22_col0\" class=\"data row22 col0\" >Imputation Type</td>\n                        <td id=\"T_3fb0a_row22_col1\" class=\"data row22 col1\" >simple</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n                        <td id=\"T_3fb0a_row23_col0\" class=\"data row23 col0\" >Iterative Imputation Iteration</td>\n                        <td id=\"T_3fb0a_row23_col1\" class=\"data row23 col1\" >None</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n                        <td id=\"T_3fb0a_row24_col0\" class=\"data row24 col0\" >Numeric Imputer</td>\n                        <td id=\"T_3fb0a_row24_col1\" class=\"data row24 col1\" >mean</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n                        <td id=\"T_3fb0a_row25_col0\" class=\"data row25 col0\" >Iterative Imputation Numeric Model</td>\n                        <td id=\"T_3fb0a_row25_col1\" class=\"data row25 col1\" >None</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n                        <td id=\"T_3fb0a_row26_col0\" class=\"data row26 col0\" >Categorical Imputer</td>\n                        <td id=\"T_3fb0a_row26_col1\" class=\"data row26 col1\" >constant</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n                        <td id=\"T_3fb0a_row27_col0\" class=\"data row27 col0\" >Iterative Imputation Categorical Model</td>\n                        <td id=\"T_3fb0a_row27_col1\" class=\"data row27 col1\" >None</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n                        <td id=\"T_3fb0a_row28_col0\" class=\"data row28 col0\" >Unknown Categoricals Handling</td>\n                        <td id=\"T_3fb0a_row28_col1\" class=\"data row28 col1\" >least_frequent</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n                        <td id=\"T_3fb0a_row29_col0\" class=\"data row29 col0\" >Normalize</td>\n                        <td id=\"T_3fb0a_row29_col1\" class=\"data row29 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n                        <td id=\"T_3fb0a_row30_col0\" class=\"data row30 col0\" >Normalize Method</td>\n                        <td id=\"T_3fb0a_row30_col1\" class=\"data row30 col1\" >None</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n                        <td id=\"T_3fb0a_row31_col0\" class=\"data row31 col0\" >Transformation</td>\n                        <td id=\"T_3fb0a_row31_col1\" class=\"data row31 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n                        <td id=\"T_3fb0a_row32_col0\" class=\"data row32 col0\" >Transformation Method</td>\n                        <td id=\"T_3fb0a_row32_col1\" class=\"data row32 col1\" >None</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n                        <td id=\"T_3fb0a_row33_col0\" class=\"data row33 col0\" >PCA</td>\n                        <td id=\"T_3fb0a_row33_col1\" class=\"data row33 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n                        <td id=\"T_3fb0a_row34_col0\" class=\"data row34 col0\" >PCA Method</td>\n                        <td id=\"T_3fb0a_row34_col1\" class=\"data row34 col1\" >None</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n                        <td id=\"T_3fb0a_row35_col0\" class=\"data row35 col0\" >PCA Components</td>\n                        <td id=\"T_3fb0a_row35_col1\" class=\"data row35 col1\" >None</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n                        <td id=\"T_3fb0a_row36_col0\" class=\"data row36 col0\" >Ignore Low Variance</td>\n                        <td id=\"T_3fb0a_row36_col1\" class=\"data row36 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n                        <td id=\"T_3fb0a_row37_col0\" class=\"data row37 col0\" >Combine Rare Levels</td>\n                        <td id=\"T_3fb0a_row37_col1\" class=\"data row37 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n                        <td id=\"T_3fb0a_row38_col0\" class=\"data row38 col0\" >Rare Level Threshold</td>\n                        <td id=\"T_3fb0a_row38_col1\" class=\"data row38 col1\" >None</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n                        <td id=\"T_3fb0a_row39_col0\" class=\"data row39 col0\" >Numeric Binning</td>\n                        <td id=\"T_3fb0a_row39_col1\" class=\"data row39 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n                        <td id=\"T_3fb0a_row40_col0\" class=\"data row40 col0\" >Remove Outliers</td>\n                        <td id=\"T_3fb0a_row40_col1\" class=\"data row40 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n                        <td id=\"T_3fb0a_row41_col0\" class=\"data row41 col0\" >Outliers Threshold</td>\n                        <td id=\"T_3fb0a_row41_col1\" class=\"data row41 col1\" >None</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n                        <td id=\"T_3fb0a_row42_col0\" class=\"data row42 col0\" >Remove Multicollinearity</td>\n                        <td id=\"T_3fb0a_row42_col1\" class=\"data row42 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n                        <td id=\"T_3fb0a_row43_col0\" class=\"data row43 col0\" >Multicollinearity Threshold</td>\n                        <td id=\"T_3fb0a_row43_col1\" class=\"data row43 col1\" >None</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n                        <td id=\"T_3fb0a_row44_col0\" class=\"data row44 col0\" >Clustering</td>\n                        <td id=\"T_3fb0a_row44_col1\" class=\"data row44 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n                        <td id=\"T_3fb0a_row45_col0\" class=\"data row45 col0\" >Clustering Iteration</td>\n                        <td id=\"T_3fb0a_row45_col1\" class=\"data row45 col1\" >None</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n                        <td id=\"T_3fb0a_row46_col0\" class=\"data row46 col0\" >Polynomial Features</td>\n                        <td id=\"T_3fb0a_row46_col1\" class=\"data row46 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n                        <td id=\"T_3fb0a_row47_col0\" class=\"data row47 col0\" >Polynomial Degree</td>\n                        <td id=\"T_3fb0a_row47_col1\" class=\"data row47 col1\" >None</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n                        <td id=\"T_3fb0a_row48_col0\" class=\"data row48 col0\" >Trignometry Features</td>\n                        <td id=\"T_3fb0a_row48_col1\" class=\"data row48 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n                        <td id=\"T_3fb0a_row49_col0\" class=\"data row49 col0\" >Polynomial Threshold</td>\n                        <td id=\"T_3fb0a_row49_col1\" class=\"data row49 col1\" >None</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n                        <td id=\"T_3fb0a_row50_col0\" class=\"data row50 col0\" >Group Features</td>\n                        <td id=\"T_3fb0a_row50_col1\" class=\"data row50 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n                        <td id=\"T_3fb0a_row51_col0\" class=\"data row51 col0\" >Feature Selection</td>\n                        <td id=\"T_3fb0a_row51_col1\" class=\"data row51 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n                        <td id=\"T_3fb0a_row52_col0\" class=\"data row52 col0\" >Feature Selection Method</td>\n                        <td id=\"T_3fb0a_row52_col1\" class=\"data row52 col1\" >classic</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n                        <td id=\"T_3fb0a_row53_col0\" class=\"data row53 col0\" >Features Selection Threshold</td>\n                        <td id=\"T_3fb0a_row53_col1\" class=\"data row53 col1\" >None</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n                        <td id=\"T_3fb0a_row54_col0\" class=\"data row54 col0\" >Feature Interaction</td>\n                        <td id=\"T_3fb0a_row54_col1\" class=\"data row54 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n                        <td id=\"T_3fb0a_row55_col0\" class=\"data row55 col0\" >Feature Ratio</td>\n                        <td id=\"T_3fb0a_row55_col1\" class=\"data row55 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n                        <td id=\"T_3fb0a_row56_col0\" class=\"data row56 col0\" >Interaction Threshold</td>\n                        <td id=\"T_3fb0a_row56_col1\" class=\"data row56 col1\" >None</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n                        <td id=\"T_3fb0a_row57_col0\" class=\"data row57 col0\" >Fix Imbalance</td>\n                        <td id=\"T_3fb0a_row57_col1\" class=\"data row57 col1\" >False</td>\n            </tr>\n            <tr>\n                        <th id=\"T_3fb0a_level0_row58\" class=\"row_heading level0 row58\" >58</th>\n                        <td id=\"T_3fb0a_row58_col0\" class=\"data row58 col0\" >Fix Imbalance Method</td>\n                        <td id=\"T_3fb0a_row58_col1\" class=\"data row58 col1\" >SMOTE</td>\n            </tr>\n    </tbody></table>","text/plain":"<pandas.io.formats.style.Styler at 0x7f10f749ef50>"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b6da669bec8499e995a2f5f87757ab8","version_major":2,"version_minor":0},"text/plain":"IntProgress(value=0, description='Processing: ', max=79)"},"metadata":{},"output_type":"display_data"},{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Initiated</th>\n      <td>. . . . . . . . . . . . . . . . . .</td>\n      <td>20:51:51</td>\n    </tr>\n    <tr>\n      <th>Status</th>\n      <td>. . . . . . . . . . . . . . . . . .</td>\n      <td>Fitting 10 Folds</td>\n    </tr>\n    <tr>\n      <th>Estimator</th>\n      <td>. . . . . . . . . . . . . . . . . .</td>\n      <td>Extreme Gradient Boosting</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                                                                         \n                                                                         \nInitiated  . . . . . . . . . . . . . . . . . .                   20:51:51\nStatus     . . . . . . . . . . . . . . . . . .           Fitting 10 Folds\nEstimator  . . . . . . . . . . . . . . . . . .  Extreme Gradient Boosting"},"metadata":{},"output_type":"display_data"},{"data":{"text/html":"<style  type=\"text/css\" >\n    #T_749a2_ th {\n          text-align: left;\n    }#T_749a2_row0_col0,#T_749a2_row0_col1,#T_749a2_row0_col2,#T_749a2_row0_col3,#T_749a2_row0_col4,#T_749a2_row0_col5,#T_749a2_row0_col6,#T_749a2_row0_col7,#T_749a2_row0_col8,#T_749a2_row1_col0,#T_749a2_row1_col1,#T_749a2_row1_col2,#T_749a2_row1_col3,#T_749a2_row1_col4,#T_749a2_row1_col5,#T_749a2_row1_col6,#T_749a2_row1_col7,#T_749a2_row1_col8,#T_749a2_row2_col0,#T_749a2_row2_col1,#T_749a2_row2_col2,#T_749a2_row2_col3,#T_749a2_row2_col4,#T_749a2_row2_col5,#T_749a2_row2_col6,#T_749a2_row2_col7,#T_749a2_row2_col8,#T_749a2_row3_col0,#T_749a2_row3_col1,#T_749a2_row3_col2,#T_749a2_row3_col3,#T_749a2_row3_col4,#T_749a2_row3_col5,#T_749a2_row3_col6,#T_749a2_row3_col7,#T_749a2_row3_col8,#T_749a2_row4_col0,#T_749a2_row4_col1,#T_749a2_row4_col2,#T_749a2_row4_col3,#T_749a2_row4_col4,#T_749a2_row4_col5,#T_749a2_row4_col6,#T_749a2_row4_col7,#T_749a2_row4_col8,#T_749a2_row5_col0,#T_749a2_row5_col1,#T_749a2_row5_col2,#T_749a2_row5_col3,#T_749a2_row5_col4,#T_749a2_row5_col5,#T_749a2_row5_col6,#T_749a2_row5_col7,#T_749a2_row5_col8,#T_749a2_row6_col0,#T_749a2_row6_col1,#T_749a2_row6_col2,#T_749a2_row6_col3,#T_749a2_row6_col4,#T_749a2_row6_col5,#T_749a2_row6_col6,#T_749a2_row6_col7,#T_749a2_row6_col8,#T_749a2_row7_col0,#T_749a2_row7_col1,#T_749a2_row7_col2,#T_749a2_row7_col3,#T_749a2_row7_col4,#T_749a2_row7_col5,#T_749a2_row7_col6,#T_749a2_row7_col7,#T_749a2_row7_col8,#T_749a2_row8_col0,#T_749a2_row8_col1,#T_749a2_row8_col2,#T_749a2_row8_col3,#T_749a2_row8_col4,#T_749a2_row8_col5,#T_749a2_row8_col6,#T_749a2_row8_col7,#T_749a2_row8_col8,#T_749a2_row9_col0,#T_749a2_row9_col1,#T_749a2_row9_col2,#T_749a2_row9_col3,#T_749a2_row9_col4,#T_749a2_row9_col5,#T_749a2_row9_col6,#T_749a2_row9_col7,#T_749a2_row9_col8,#T_749a2_row10_col0,#T_749a2_row10_col1,#T_749a2_row10_col2,#T_749a2_row10_col3,#T_749a2_row10_col4,#T_749a2_row10_col5,#T_749a2_row10_col6,#T_749a2_row10_col7,#T_749a2_row10_col8,#T_749a2_row11_col0,#T_749a2_row11_col1,#T_749a2_row11_col2,#T_749a2_row11_col3,#T_749a2_row11_col4,#T_749a2_row11_col5,#T_749a2_row11_col6,#T_749a2_row11_col7,#T_749a2_row11_col8{\n            text-align:  left;\n        }</style><table id=\"T_749a2_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >Accuracy</th>        <th class=\"col_heading level0 col2\" >AUC</th>        <th class=\"col_heading level0 col3\" >Recall</th>        <th class=\"col_heading level0 col4\" >Prec.</th>        <th class=\"col_heading level0 col5\" >F1</th>        <th class=\"col_heading level0 col6\" >Kappa</th>        <th class=\"col_heading level0 col7\" >MCC</th>        <th class=\"col_heading level0 col8\" >TT (Sec)</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_749a2_level0_row0\" class=\"row_heading level0 row0\" >gbc</th>\n                        <td id=\"T_749a2_row0_col0\" class=\"data row0 col0\" >Gradient Boosting Classifier</td>\n                        <td id=\"T_749a2_row0_col1\" class=\"data row0 col1\" >0.7637</td>\n                        <td id=\"T_749a2_row0_col2\" class=\"data row0 col2\" >0.8415</td>\n                        <td id=\"T_749a2_row0_col3\" class=\"data row0 col3\" >0.6000</td>\n                        <td id=\"T_749a2_row0_col4\" class=\"data row0 col4\" >0.7117</td>\n                        <td id=\"T_749a2_row0_col5\" class=\"data row0 col5\" >0.6356</td>\n                        <td id=\"T_749a2_row0_col6\" class=\"data row0 col6\" >0.4653</td>\n                        <td id=\"T_749a2_row0_col7\" class=\"data row0 col7\" >0.4797</td>\n                        <td id=\"T_749a2_row0_col8\" class=\"data row0 col8\" >0.0530</td>\n            </tr>\n            <tr>\n                        <th id=\"T_749a2_level0_row1\" class=\"row_heading level0 row1\" >lda</th>\n                        <td id=\"T_749a2_row1_col0\" class=\"data row1 col0\" >Linear Discriminant Analysis</td>\n                        <td id=\"T_749a2_row1_col1\" class=\"data row1 col1\" >0.7560</td>\n                        <td id=\"T_749a2_row1_col2\" class=\"data row1 col2\" >0.8087</td>\n                        <td id=\"T_749a2_row1_col3\" class=\"data row1 col3\" >0.5684</td>\n                        <td id=\"T_749a2_row1_col4\" class=\"data row1 col4\" >0.6978</td>\n                        <td id=\"T_749a2_row1_col5\" class=\"data row1 col5\" >0.6194</td>\n                        <td id=\"T_749a2_row1_col6\" class=\"data row1 col6\" >0.4439</td>\n                        <td id=\"T_749a2_row1_col7\" class=\"data row1 col7\" >0.4538</td>\n                        <td id=\"T_749a2_row1_col8\" class=\"data row1 col8\" >0.0090</td>\n            </tr>\n            <tr>\n                        <th id=\"T_749a2_level0_row2\" class=\"row_heading level0 row2\" >lr</th>\n                        <td id=\"T_749a2_row2_col0\" class=\"data row2 col0\" >Logistic Regression</td>\n                        <td id=\"T_749a2_row2_col1\" class=\"data row2 col1\" >0.7542</td>\n                        <td id=\"T_749a2_row2_col2\" class=\"data row2 col2\" >0.8151</td>\n                        <td id=\"T_749a2_row2_col3\" class=\"data row2 col3\" >0.5684</td>\n                        <td id=\"T_749a2_row2_col4\" class=\"data row2 col4\" >0.6912</td>\n                        <td id=\"T_749a2_row2_col5\" class=\"data row2 col5\" >0.6193</td>\n                        <td id=\"T_749a2_row2_col6\" class=\"data row2 col6\" >0.4410</td>\n                        <td id=\"T_749a2_row2_col7\" class=\"data row2 col7\" >0.4489</td>\n                        <td id=\"T_749a2_row2_col8\" class=\"data row2 col8\" >0.3650</td>\n            </tr>\n            <tr>\n                        <th id=\"T_749a2_level0_row3\" class=\"row_heading level0 row3\" >ridge</th>\n                        <td id=\"T_749a2_row3_col0\" class=\"data row3 col0\" >Ridge Classifier</td>\n                        <td id=\"T_749a2_row3_col1\" class=\"data row3 col1\" >0.7504</td>\n                        <td id=\"T_749a2_row3_col2\" class=\"data row3 col2\" >0.0000</td>\n                        <td id=\"T_749a2_row3_col3\" class=\"data row3 col3\" >0.5579</td>\n                        <td id=\"T_749a2_row3_col4\" class=\"data row3 col4\" >0.6900</td>\n                        <td id=\"T_749a2_row3_col5\" class=\"data row3 col5\" >0.6110</td>\n                        <td id=\"T_749a2_row3_col6\" class=\"data row3 col6\" >0.4311</td>\n                        <td id=\"T_749a2_row3_col7\" class=\"data row3 col7\" >0.4405</td>\n                        <td id=\"T_749a2_row3_col8\" class=\"data row3 col8\" >0.0080</td>\n            </tr>\n            <tr>\n                        <th id=\"T_749a2_level0_row4\" class=\"row_heading level0 row4\" >rf</th>\n                        <td id=\"T_749a2_row4_col0\" class=\"data row4 col0\" >Random Forest Classifier</td>\n                        <td id=\"T_749a2_row4_col1\" class=\"data row4 col1\" >0.7469</td>\n                        <td id=\"T_749a2_row4_col2\" class=\"data row4 col2\" >0.8303</td>\n                        <td id=\"T_749a2_row4_col3\" class=\"data row4 col3\" >0.5263</td>\n                        <td id=\"T_749a2_row4_col4\" class=\"data row4 col4\" >0.7017</td>\n                        <td id=\"T_749a2_row4_col5\" class=\"data row4 col5\" >0.5922</td>\n                        <td id=\"T_749a2_row4_col6\" class=\"data row4 col6\" >0.4156</td>\n                        <td id=\"T_749a2_row4_col7\" class=\"data row4 col7\" >0.4305</td>\n                        <td id=\"T_749a2_row4_col8\" class=\"data row4 col8\" >0.3020</td>\n            </tr>\n            <tr>\n                        <th id=\"T_749a2_level0_row5\" class=\"row_heading level0 row5\" >ada</th>\n                        <td id=\"T_749a2_row5_col0\" class=\"data row5 col0\" >Ada Boost Classifier</td>\n                        <td id=\"T_749a2_row5_col1\" class=\"data row5 col1\" >0.7468</td>\n                        <td id=\"T_749a2_row5_col2\" class=\"data row5 col2\" >0.7894</td>\n                        <td id=\"T_749a2_row5_col3\" class=\"data row5 col3\" >0.5579</td>\n                        <td id=\"T_749a2_row5_col4\" class=\"data row5 col4\" >0.6802</td>\n                        <td id=\"T_749a2_row5_col5\" class=\"data row5 col5\" >0.6080</td>\n                        <td id=\"T_749a2_row5_col6\" class=\"data row5 col6\" >0.4247</td>\n                        <td id=\"T_749a2_row5_col7\" class=\"data row5 col7\" >0.4326</td>\n                        <td id=\"T_749a2_row5_col8\" class=\"data row5 col8\" >0.0470</td>\n            </tr>\n            <tr>\n                        <th id=\"T_749a2_level0_row6\" class=\"row_heading level0 row6\" >et</th>\n                        <td id=\"T_749a2_row6_col0\" class=\"data row6 col0\" >Extra Trees Classifier</td>\n                        <td id=\"T_749a2_row6_col1\" class=\"data row6 col1\" >0.7430</td>\n                        <td id=\"T_749a2_row6_col2\" class=\"data row6 col2\" >0.8076</td>\n                        <td id=\"T_749a2_row6_col3\" class=\"data row6 col3\" >0.5263</td>\n                        <td id=\"T_749a2_row6_col4\" class=\"data row6 col4\" >0.6930</td>\n                        <td id=\"T_749a2_row6_col5\" class=\"data row6 col5\" >0.5900</td>\n                        <td id=\"T_749a2_row6_col6\" class=\"data row6 col6\" >0.4092</td>\n                        <td id=\"T_749a2_row6_col7\" class=\"data row6 col7\" >0.4226</td>\n                        <td id=\"T_749a2_row6_col8\" class=\"data row6 col8\" >0.2810</td>\n            </tr>\n            <tr>\n                        <th id=\"T_749a2_level0_row7\" class=\"row_heading level0 row7\" >dt</th>\n                        <td id=\"T_749a2_row7_col0\" class=\"data row7 col0\" >Decision Tree Classifier</td>\n                        <td id=\"T_749a2_row7_col1\" class=\"data row7 col1\" >0.7207</td>\n                        <td id=\"T_749a2_row7_col2\" class=\"data row7 col2\" >0.6971</td>\n                        <td id=\"T_749a2_row7_col3\" class=\"data row7 col3\" >0.6158</td>\n                        <td id=\"T_749a2_row7_col4\" class=\"data row7 col4\" >0.6084</td>\n                        <td id=\"T_749a2_row7_col5\" class=\"data row7 col5\" >0.6074</td>\n                        <td id=\"T_749a2_row7_col6\" class=\"data row7 col6\" >0.3916</td>\n                        <td id=\"T_749a2_row7_col7\" class=\"data row7 col7\" >0.3958</td>\n                        <td id=\"T_749a2_row7_col8\" class=\"data row7 col8\" >0.0080</td>\n            </tr>\n            <tr>\n                        <th id=\"T_749a2_level0_row8\" class=\"row_heading level0 row8\" >knn</th>\n                        <td id=\"T_749a2_row8_col0\" class=\"data row8 col0\" >K Neighbors Classifier</td>\n                        <td id=\"T_749a2_row8_col1\" class=\"data row8 col1\" >0.7206</td>\n                        <td id=\"T_749a2_row8_col2\" class=\"data row8 col2\" >0.7409</td>\n                        <td id=\"T_749a2_row8_col3\" class=\"data row8 col3\" >0.5421</td>\n                        <td id=\"T_749a2_row8_col4\" class=\"data row8 col4\" >0.6205</td>\n                        <td id=\"T_749a2_row8_col5\" class=\"data row8 col5\" >0.5716</td>\n                        <td id=\"T_749a2_row8_col6\" class=\"data row8 col6\" >0.3690</td>\n                        <td id=\"T_749a2_row8_col7\" class=\"data row8 col7\" >0.3741</td>\n                        <td id=\"T_749a2_row8_col8\" class=\"data row8 col8\" >0.0720</td>\n            </tr>\n            <tr>\n                        <th id=\"T_749a2_level0_row9\" class=\"row_heading level0 row9\" >nb</th>\n                        <td id=\"T_749a2_row9_col0\" class=\"data row9 col0\" >Naive Bayes</td>\n                        <td id=\"T_749a2_row9_col1\" class=\"data row9 col1\" >0.6666</td>\n                        <td id=\"T_749a2_row9_col2\" class=\"data row9 col2\" >0.7410</td>\n                        <td id=\"T_749a2_row9_col3\" class=\"data row9 col3\" >0.2211</td>\n                        <td id=\"T_749a2_row9_col4\" class=\"data row9 col4\" >0.6445</td>\n                        <td id=\"T_749a2_row9_col5\" class=\"data row9 col5\" >0.3144</td>\n                        <td id=\"T_749a2_row9_col6\" class=\"data row9 col6\" >0.1547</td>\n                        <td id=\"T_749a2_row9_col7\" class=\"data row9 col7\" >0.2033</td>\n                        <td id=\"T_749a2_row9_col8\" class=\"data row9 col8\" >0.0070</td>\n            </tr>\n            <tr>\n                        <th id=\"T_749a2_level0_row10\" class=\"row_heading level0 row10\" >svm</th>\n                        <td id=\"T_749a2_row10_col0\" class=\"data row10 col0\" >SVM - Linear Kernel</td>\n                        <td id=\"T_749a2_row10_col1\" class=\"data row10 col1\" >0.5939</td>\n                        <td id=\"T_749a2_row10_col2\" class=\"data row10 col2\" >0.0000</td>\n                        <td id=\"T_749a2_row10_col3\" class=\"data row10 col3\" >0.3842</td>\n                        <td id=\"T_749a2_row10_col4\" class=\"data row10 col4\" >0.4301</td>\n                        <td id=\"T_749a2_row10_col5\" class=\"data row10 col5\" >0.3233</td>\n                        <td id=\"T_749a2_row10_col6\" class=\"data row10 col6\" >0.0932</td>\n                        <td id=\"T_749a2_row10_col7\" class=\"data row10 col7\" >0.1100</td>\n                        <td id=\"T_749a2_row10_col8\" class=\"data row10 col8\" >0.0090</td>\n            </tr>\n            <tr>\n                        <th id=\"T_749a2_level0_row11\" class=\"row_heading level0 row11\" >qda</th>\n                        <td id=\"T_749a2_row11_col0\" class=\"data row11 col0\" >Quadratic Discriminant Analysis</td>\n                        <td id=\"T_749a2_row11_col1\" class=\"data row11 col1\" >0.5224</td>\n                        <td id=\"T_749a2_row11_col2\" class=\"data row11 col2\" >0.4994</td>\n                        <td id=\"T_749a2_row11_col3\" class=\"data row11 col3\" >0.4368</td>\n                        <td id=\"T_749a2_row11_col4\" class=\"data row11 col4\" >0.3139</td>\n                        <td id=\"T_749a2_row11_col5\" class=\"data row11 col5\" >0.3161</td>\n                        <td id=\"T_749a2_row11_col6\" class=\"data row11 col6\" >0.0090</td>\n                        <td id=\"T_749a2_row11_col7\" class=\"data row11 col7\" >-0.0083</td>\n                        <td id=\"T_749a2_row11_col8\" class=\"data row11 col8\" >0.0100</td>\n            </tr>\n    </tbody></table>","text/plain":"<pandas.io.formats.style.Styler at 0x7f1134c26b90>"},"metadata":{},"output_type":"display_data"}],"source":["from pycaret.datasets import get_data\n","data = get_data('diabetes')\n","# initializing setup\n","from pycaret.classification import *\n","clf1 = setup(data, target = 'Class variable', log_experiment = True, experiment_name = 'diabetes1')\n","# compare baseline\n","top5 = compare_models()\n","# checkout logs in csv\n","logs = get_logs(save=True) # To save csv in working directory"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["logs"]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.7 64-bit ('base': conda)","name":"python377jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"orig_nbformat":3},"nbformat":4,"nbformat_minor":0}